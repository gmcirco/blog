{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name answerdotai/ModernBERT-base. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util,  losses\n",
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.similarity_functions import SimilarityFunction\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"answerdotai/ModernBERT-base\"\n",
    "TRAIN_DATA = \"C:/Users/gioc4/Documents/blog/data/falls/falls.csv\"\n",
    "EVAL_DATA = \"C:/Users/gioc4/Documents/blog/data/falls/neis.csv\"\n",
    "MAX_TOKEN_LENGTH = 256\n",
    "DATA_SIZE = 1000\n",
    "TRAIN_SIZE = .90\n",
    "\n",
    "# load data\n",
    "falls_data = pd.read_csv(TRAIN_DATA).head(DATA_SIZE)\n",
    "neis_data = pd.read_csv(EVAL_DATA).head(DATA_SIZE)\n",
    "\n",
    "# define a sentence transformer model\n",
    "model = SentenceTransformer(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to set up a training dataset based on the cosine similarity between\n",
    "# observed falls (falls data) and general cases from the NEIS\n",
    "\n",
    "# we want the observations to be agnostic to patient age, so we remove those\n",
    "# define remappings of abbreviations\n",
    "# and strings to remove from narratives\n",
    "\n",
    "remap = {\n",
    "    \"FX\": \"FRACTURE\",\n",
    "    \"INJ\": \"INJURY\",\n",
    "    \"LAC\": \"LACERATION\",\n",
    "    \"CONT\": \"CONTUSION\",\n",
    "    \"CHI\" : \"CLOSED HEAD INJURY\",\n",
    "    \"ETOH\": \"ALCOHOL\",\n",
    "    \"SDH\": \"SUBDURAL HEMATOMA\",\n",
    "    \"NH\": \"NURSING HOME\",\n",
    "    \"PT\": \"PATIENT\",\n",
    "    \"LT\": \"LEFT\",\n",
    "    \"RT\": \"RIGHT\",\n",
    "    \"&\" : \" AND \"\n",
    "}\n",
    "str_remove = \"YOM|YOF|MOM|MOF|C/O|S/P|H/O|DX\"\n",
    "\n",
    "\n",
    "def process_text(txt):\n",
    "    words = txt.split()\n",
    "    new_words = [remap.get(word, word) for word in words]\n",
    "    txt = \" \".join(new_words)\n",
    "\n",
    "    txt = re.sub(\"[^a-zA-Z ]\", \"\", txt)\n",
    "    txt = re.sub(str_remove, \"\", txt)\n",
    "\n",
    "    return re.sub(r\"^\\s+\", \"\", txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "falls = falls_data['narrative'].apply(process_text).tolist()\n",
    "neis = neis_data['Narrative_1'].apply(process_text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m embed_neis \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(neis)\n\u001b[0;32m      4\u001b[0m cos_sim \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mcos_sim(embed_falls, embed_neis)\n\u001b[1;32m----> 6\u001b[0m diagonal_sim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiagonal(cos_sim)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# encode verified falls, and neis narratives\n",
    "embed_falls = model.encode(falls)\n",
    "embed_neis = model.encode(neis)\n",
    "cos_sim = util.cos_sim(embed_falls, embed_neis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gioc4\\AppData\\Local\\Temp\\ipykernel_5356\\1255315025.py:6: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  dists = np.array(dists).tolist()\n"
     ]
    }
   ],
   "source": [
    "# get just the pairwise comparisons for now\n",
    "dists = torch.diagonal(cos_sim)\n",
    "d_min, d_max = dists.min(), dists.max()\n",
    "\n",
    "dists = (dists - d_min)/(d_max - d_min)\n",
    "dists = np.array(dists).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert to a train dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": falls[0:899],\n",
    "    \"sentence2\": neis[0:899],\n",
    "    \"score\": dists[0:899]\n",
    "})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": falls[900:1000],\n",
    "    \"sentence2\": neis[900:1000],\n",
    "    \"score\": dists[900:1000]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'FELL OUT OF A CHAIR AT THE NURSING HOME HIT HER HIP CUT HER WRIST CONTUSION HIPLAC WRIST',\n",
       " 'sentence2': 'ROLLED OUT BEDHIT HEAD ON TABLEFACIAL FXLAC',\n",
       " 'score': 0.5013291835784912}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=eval_dataset[\"sentence1\"],\n",
    "    sentences2=eval_dataset[\"sentence2\"],\n",
    "    scores=eval_dataset[\"score\"],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    name=\"sts-dev\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gioc4\\Anaconda3\\envs\\bert_models\\Lib\\site-packages\\transformers\\training_args.py:1573: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [15:31<00:00, 16.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 931.7774, 'train_samples_per_second': 1.93, 'train_steps_per_second': 0.062, 'train_loss': 0.09221398419347303, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=58, training_loss=0.09221398419347303, metrics={'train_runtime': 931.7774, 'train_samples_per_second': 1.93, 'train_steps_per_second': 0.062, 'total_flos': 0.0, 'train_loss': 0.09221398419347303, 'epoch': 2.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_ratio=0.1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"sts\",\n",
    ")\n",
    "\n",
    "# 6. Create the trainer & start training\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:10<00:00,  2.38s/it]c:\\Users\\gioc4\\Anaconda3\\envs\\bert_models\\Lib\\site-packages\\sentence_transformers\\evaluation\\EmbeddingSimilarityEvaluator.py:206: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_pearson, _ = pearsonr(labels, scores)\n",
      "c:\\Users\\gioc4\\Anaconda3\\envs\\bert_models\\Lib\\site-packages\\sentence_transformers\\evaluation\\EmbeddingSimilarityEvaluator.py:207: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_spearman, _ = spearmanr(labels, scores)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:20<00:00,  5.01s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(eval_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
