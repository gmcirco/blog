{
  "hash": "efbf6c88c0585c47e05a45ac9c700baa",
  "result": {
    "markdown": "---\ntitle: \"Generating Spatial Risk Features using R\"\nsubtitle: \"Creating 'RTM' style map data\"\nauthor: \"Gio Circo, Ph.D.\"\ndate: 2023-10-6\nformat: \n    html:\n        self-contained: false\n        code-fold: true\n        mainfont: \"Roboto\"\n        section-divs: true\n        toc: true\n        title-block-banner: true\ncategories:\n  - R\n  - Spatial Statistics\nbibliography: refs.bib\ntheme: flatly\nimage: \"city.jpg\"\n---\n\n::: {.cell}\n\n:::\n\n\n## Spatial Features\n\nIn criminology there is a considerable research on the role that fixed spatial\nfeatures in the environment have on crime. These spatial risk factors have \ncriminogenic qualities that make them \"attractors\" or \"generators\"[@brantingham1995criminality]. \nAbsent some change, these places typically contribute a disproportionate share of crime that is\nlargely stable over time[@sherman1989hot].\nThe classic example is a bar or night club. Alcohol plays a large role in a \nlot of crime, and locations where many people congregate and become intoxicated \nalso have higher incidences of crime. We can use information about the environment to\nhelp solve problems or prioritize patrol areas.\n\nOne challenge in research is obtaining the point locations for these features.\nGenerally when we perform some kind of spatial analysis we have a study area \n(e.g. a city or other boundary file) and a set of labeled point features \ncorresponding to the locations of interest. However, reliable places to get this\ninformation is often hard to come by. Some cities provide open data portals\nwith commercial information, but these are typically limited to larger cities.\nIn my work I've had people ask how to get spatial risk factors for their research,\noften times for something related to the \"Risk Terrain Modeling\" approach of \nspatial analysis. I've worked on a few projects now where I've had to generate\nthese myself, and have had some success using open data sources like Google to\nhelp with it.\n\n## Querying Google Places\n\nGoogle has a lot of paid API services which are quite useful for researchers. In \nmost cases there is a free tier, and for smaller one-off projects this makes their\nAPI services attractive for research. Let's walk through an example of how we \nmight do this. For our example we will use the Swedish city of Malmö \n(which, incidentially is a very lovely city I've been lucky enough to visit). \nWe have a shapefile that looks like this:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](rtm_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nOur goal is to query the[**Google Places API**](https://developers.google.com/maps/documentation/places/web-service/overview) \nto get the locations of criminogenic\nspatial risk factors (here, bars and gas stations). One significant limitation\nwith the Google Places API is that there is a limit to the number of locations\nthat will show up for a single query. This means if you ran the query on the\nentire city, it would only return up to 20 locations. However, we can bypass\nthis by running multiple queries on smaller spatial regions. Other bloggers have\nprovided similar advice as well (see [**here**](https://blog.apify.com/google-maps-how-to-overcome-google-api-limit-120-places/) and [**here**](https://andrewpwheeler.com/2021/06/20/using-google-places-api-in-criminology-research/)).\n\nTo do the actual interfacing with the Google Places API we will use the very\nhandy [**googleway**](https://cran.r-project.org/web/packages/googleway/vignettes/googleway-vignette.html)\npackage.\n\n### Splitting up into a grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# GOOGLE PLACES API CODE\n# ================================================= #\n# Giovanni Circo\n# gmcirco42@gmail.com\n#\n# Code to query google place api\n# Divides a boundry shapefile into grid cells\n# of radius r, then queries the api for each cell\n#\n# NOTE:\n# Only requires a free version of the API. Doesn't\n# incur any costs.\n# ================================================= #\n\nlibrary(googleway)\nlibrary(sf)\nlibrary(tidyverse)\n\n# API Key\n# instructions here:\n# https://developers.google.com/maps/documentation/places/web-service/get-api-key\nmykey <- \"[INSERT GOOGLE PLACES API KEY HERE]\"\n\n# Location shapefile\nboundry <- st_read(\"...\\DeSo_Malmö.shp\")\n\n# specify grid size (meters)\nr <- 1200\n\n# Make a grid\nboundry_grid <- st_make_grid(boundry, cellsize = r)\nboundry_grid <- boundry_grid[boundry]\n\n# Transform to lat\\lon\n# Extract coords\narea_coords <- st_transform(boundry_grid, crs = 4326) %>%\n  st_centroid() %>%\n  st_coordinates() %>%\n  data.frame() %>%\n  select(lat = Y, lon = X)\n```\n:::\n\n\nWe can divide the city into a series of grids, then iterate through each grid\ncell and query within it. This way we are more likely to obtain all of the \nrelevant features in that grid cell without hitting the limit. Here, I create\n150 1200 square meter grid cells, which gives us something like this:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](rtm_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nIn addition we extract the X-Y coordinates for the grid centroid, which we will\nuse as our location for the API query. This means we hit the API 150 times, once\nfor each grid cell. This is well within the free number that Google allows. \n\n### Querying our features\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# EXTRACT FEATURES ON GRID\n#----------------------------#\n\n# Supported place type names:\n# https://developers.google.com/maps/documentation/places/web-service/supported_types\n# Features: gas_station, bar, liquor_store, night_club, pharmacy, restaurant\n\n# Specify feature type\n# number of grid cells\nfeature <- \"bar\"\nn <- nrow(area_coords)\n\n# First, set up function to query google places\n# for each grid centroid\n# add to a list\n\narea_list <- list()\nfor(i in 1:n){\n  \n  area_list[[i]] <-\n    google_places(location = unlist(area_coords[i,]),\n                  place_type = feature,\n                  radius = r,\n                  key = mykey)\n}\n\n# Function to convert results from above\n# to a dataframe suitable for rbinding\n# then conversion to an sf object\nconvert_to_dataframe <-\n  function(x) {\n    \na <- x$results\n\nb <- tibble(\n  lat = a$geometry$location$lat,\n  lon = a$geometry$location$lng,\n  name = a$name,\n  types = a$types,\n  address = a$vicinity,\n  place_id = a$place_id\n)\n\nreturn(b)\n  }\n\n# Rbind the results, and then un-nest on feature type\n# This creates a long-form dataframe that you can then filter\n# based on feature type\narea_dataframe <-\n  do.call(rbind, lapply(area_list, convert_to_dataframe)) %>%\n  distinct(place_id, .keep_all = TRUE) %>%\n  unnest(types)\n\n# Get just feature requested\nfeature_out <- area_dataframe %>%\n  filter(types %in% feature) %>%\n  distinct(address, .keep_all = TRUE)\n```\n:::\n\n\nWe can use the code above to iterate through each grid cell, hit the API, and \nthen store the results in a list. I include a few helper functions to assist \nwith pulling out the names and coordinates, binding them into a dataframe, \nand setting them up to export. The key bit of code is below, which is the part\nthat queries the API for each of the grid cells:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\narea_list <- list()\nfor(i in 1:n){\n  \n  area_list[[i]] <-\n    google_places(location = unlist(area_coords[i,]),\n                  place_type = feature,\n                  radius = r,\n                  key = mykey)\n}\n```\n:::\n\n\n## Calculating Grid Cell Distances\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompute_distance <- function(grid, feature){\n  # get nearest point from grid to feature\n  nearest <- st_nearest_feature(grid,feature)\n  nearest_dist <- st_distance(grid, feature[nearest,], by_element = TRUE)\n  \n  return(nearest_dist)\n}\n\n# specify grid size (meters)\nr <- 250\n\n# Make a city grid\ncity <- st_make_grid(boundry, cellsize = r, square = FALSE)\ncity <- city[boundry]\n\n# get distances\nbar_dist <- compute_distance(city, bar)\ngas_dist <- compute_distance(city, gas)\n  \n# create long-form dataframe\ntbl <- tibble(city) %>%\n  mutate(bar = bar_dist,\n         gas_station = gas_dist) %>%\n  pivot_longer(-city, \n               names_to = \"feature\", \n               values_to = \"dist\") %>%\n  mutate(dist = as.numeric(dist)) %>%\n  st_as_sf()\n```\n:::\n\n\nNow that we have our city boundary and our spatial risk factors, all we need to \ndo now is compute the distance from each grid cell to its nearest risk factor.\nIn the end, what we will want is a dataframe with grid cell ids, and columns\ncorresponding to distance to the nearest feature. After merging them, we can \ncreate a nice map like this - showing the location sand distances of\nour risk factors.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](rtm_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nYou can then use these features in other kinds of spatial risk models (for a great walk through, see [@wheeler2021mapping].The big advantage of this approach is that you have the flexibility to implement any kind of model you want at this point - whether it is a conventional RTM model, or a [**boosted tree model**](https://github.com/gmcirco/quickGrid). \n\n## Full Code\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# GOOGLE PLACES API CODE\n# ================================================= #\n# Giovanni Circo\n# gmcirco42@gmail.com\n#\n# Code to query google place api\n# Divides a boundry shapefile into grid cells\n# of radius r, then queries the api for each cell\n#\n# NOTE:\n# Only requires a free version of the API. Doesn't\n# incur any costs.\n# ================================================= #\n\nlibrary(googleway)\nlibrary(sf)\nlibrary(tidyverse)\n\n# API Key\n# instructions here:\n# https://developers.google.com/maps/documentation/places/web-service/get-api-key\nmykey <- \"[INSERT GOOGLE PLACES API KEY HERE]\"\n\n# Location shapefile\nboundry <- st_read(\"DeSo_Malmö.shp\")\n\n# specify grid size (meters)\nr <- 1200\n\n# Make a grid\nboundry_grid <- st_make_grid(boundry, cellsize = r)\nboundry_grid <- boundry_grid[boundry]\n\n# Transform to lat\\lon\n# Extract coords\narea_coords <- st_transform(boundry_grid, crs = 4326) %>%\n  st_centroid() %>%\n  st_coordinates() %>%\n  data.frame() %>%\n  select(lat = Y, lon = X)\n\nplot(boundry_grid)\n  \n# EXTRACT FEATURES ON GRID\n#----------------------------#\n\n# Supported place type names:\n# https://developers.google.com/maps/documentation/places/web-service/supported_types\n# Features: gas_station, bar, liquor_store, night_club, pharmacy, restaurant\n\n# Specify feature type\n# number of grid cells\nfeature <- \"bar\"\nn <- nrow(area_coords)\n\n# First, set up function to query google places\n# for each grid centroid\n# add to a list\n\narea_list <- list()\nfor(i in 1:n){\n  \n  area_list[[i]] <-\n    google_places(location = unlist(area_coords[i,]),\n                  place_type = feature,\n                  radius = r,\n                  key = mykey)\n}\n\n# Function to convert results from above\n# to a dataframe suitable for rbinding\n# then conversion to an sf object\nconvert_to_dataframe <-\n  function(x) {\n    \na <- x$results\n\nb <- tibble(\n  lat = a$geometry$location$lat,\n  lon = a$geometry$location$lng,\n  name = a$name,\n  types = a$types,\n  address = a$vicinity,\n  place_id = a$place_id\n)\n\nreturn(b)\n  }\n\n# Rbind the results, and then un-nest on feature type\n# This creates a long-form dataframe that you can then filter\n# based on feature type\narea_dataframe <-\n  do.call(rbind, lapply(area_list, convert_to_dataframe)) %>%\n  distinct(place_id, .keep_all = TRUE) %>%\n  unnest(types)\n\n# Get just feature requested\nfeature_out <- area_dataframe %>%\n  filter(types %in% feature) %>%\n  distinct(address, .keep_all = TRUE)\n\n# Now export as a shapefile\n# re-assign the crs of the boundry shapefile\nfeature_out %>%\n  st_as_sf(coords = c('lon','lat'), crs = 4326) %>%\n  st_transform(crs = st_crs(boundry)) %>%\n  st_write(paste0(\"Desktop\\\\\",feature,\".shp\"))\n```\n:::",
    "supporting": [
      "rtm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}