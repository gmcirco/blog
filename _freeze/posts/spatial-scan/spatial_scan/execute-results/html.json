{
  "hash": "05b7bf5bc355b5debe016eac4b84d1fe",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Re-Discovering Spatial Scan Statistics\"\nsubtitle: \"Detecting 'hot spots' of SIDS cases\"\nauthor: Gio Circo, Ph.D.\ndate: 2025-10-24\ncategories:\n  - R\n  - Anomaly Detection\nformat: \n    html:\n        self-contained: true\n        code-fold: false\n        mainfont: \"Roboto\"\n        section-divs: true\n        toc: true\n        title-block-banner: true\n        mermaid:\n            theme: neutral\ntheme: flatly\nimage: nc_map.png\n---\n\n\n\n## Spatial Scan Statistics\n\nSpatial scan statistics were one of the first topics I studied in grad school. The\n\n## Replicating the NC SIDS Study\n\n### Identifying high clusters\n\nSo the basic workflow is as follows:\n\n1.  The spatial scan works by passing an ellipse of radius $r$ over each county centroid $c$.\n2.  For each county $c$ we compute the bernoulli log-likelihood ratio within $r$ to the remainder of the study region.\n3.  We then repeat steps 1&2 for a fixed value of steps.\n4.  The primary cluster is the ellipse which maximizes the bernoulli log-likelihood\n\nBelow you can see how I define some constants. I define a minimum and maximum ellipse radius in feet (here I am just using a circle), along with the number of steps we take between the minimum and maximum size. The `ELLIPSE_SIZE_STEPS` gives us a vector of 20 radii to pass over each of the counties. So for 100 counties over 20 different size steps, we get 2000\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nMIN_ELLIPSE_SIZE = 2e5\nMAX_ELLIPSE_SIZE = 1e6\nELLIPSE_NUM_STEPS = 20\nELLIPSE_SIZE_STEPS = round(seq(MIN_ELLIPSE_SIZE, MAX_ELLIPSE_SIZE, length.out = ELLIPSE_NUM_STEPS))\n```\n:::\n\n\nThe code below performs the loop and adds the results to a dataframe `llr_df`. This will allow us to quickly sort and pull the results.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnc <- nc %>%\n  mutate(rate = (SID74 / BIR74) * 1000)\n\n# get county centroids\ncentroids <- st_centroid(nc)\n\nllr_df <- tibble()\n\nfor (j in seq_along(ELLIPSE_SIZE_STEPS)) {\n  ellipse_size <- ELLIPSE_SIZE_STEPS[j]\n  \n  llr_list <- vector(\"list\", nrow(centroids))\n  \n  for (i in seq_len(nrow(centroids))) {\n    # 1 choose a single county\n    buff <- st_buffer(centroids[i, ], ellipse_size)\n    \n    # 2 get all counties within 'buff'\n    z <- centroids[buff, ]\n    z_idx <- centroids$CNTY_ID %in% z$CNTY_ID\n    G <- centroids[!z_idx, ]\n    \n    # compute rates\n    Z <- compute_rate(z)\n    A <- compute_rate(G)\n    \n    c <- Z$x\n    n <- Z$n\n    C <- A$x + c\n    N <- A$n + n\n    \n    # store county index and log likelihood ratio\n    llr_df <- bind_rows(\n      llr_df,\n      tibble(\n        idx = i,\n        llr = bernoulli_llr(c, n, C, N),\n        idx_ellipse_size = as.character(j),\n        cases = c,\n        births = n\n      ),\n    )\n  }\n}\n```\n:::\n\n\nAfter running this we have a fully populated dataframe containing the bernoulli log-likelihood for each potential cluster centroid, the size of the ellipse around that centroid, and the number of births and deaths in that cluster. For example the output looks something like this:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 5\n    idx   llr idx_ellipse_size cases births\n  <int> <dbl> <chr>            <dbl>  <dbl>\n1     1 0     1                   20  12632\n2     2 0     1                   18  12590\n3     3 0     1                   43  28631\n4     4 0     1                   11   5624\n5     5 2.22  1                   39  13882\n6     6 0.925 1                   34  13541\n```\n\n\n:::\n:::\n\n\nTo identify the primary cluster we just need to select the maximum log-likelihood:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# get the most likely cluster & select its buffer\nidx_max_llr <- llr_df$idx[llr_df$llr == max(llr_df$llr)]\nidx_max_buff <- as.numeric(llr_df$idx_ellipse_size[llr_df$llr == max(llr_df$llr)])\nnew_buff <- st_buffer(centroids[idx_max_llr, ], ELLIPSE_SIZE_STEPS[idx_max_buff])\n\n# compute the rate\nllr_df$rate <- (llr_df$cases / llr_df$births)*1000\n```\n:::\n\n\n...and plot it:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](spatial_scan_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nHere we see that the location selected is a cluster of 6 counties centered on Robeson county. This region observed 127 cases of SIDS out of 45,976 live births which is a rate of 2.76 cases per 1,000 births. This is in comparison to the global rate for North Carolina at 2.02 per 1,000. To note - my numbers here don't line up exactly with the one from Kulldorff's 1997 paper. I think the sample data I am working with is slightly different. However, more importantly, the primary cluster I identified contains the exact same counties in his paper. So our bit of reverse engineering worked.\n\nMaybe this isn't the most insightful blog post I've ever done, but I always find it useful to dig into old methods and confirm I understand how they actually work. I've learned so much more trying to translate the mathematical method into code than just pure reading.",
    "supporting": [
      "spatial_scan_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}