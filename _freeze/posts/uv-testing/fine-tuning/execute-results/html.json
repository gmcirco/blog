{
  "hash": "1b825b0085eac10293f5891cc8e0c198",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Fine Tuning Your LLM for Fun and Profit\"\nsubtitle: \"Part I: Building a working model\"\nauthor: Gio Circo, Ph.D.\ndate: 2025-5-27\ncategories:\n  - Python\n  - Data Science Applications\n  - Large Language Models\nformat: \n    html:\n        self-contained: true\n        code-fold: false\n        mainfont: \"Roboto\"\n        section-divs: true\n        toc: true\n        title-block-banner: true\n        mermaid:\n            theme: neutral\ntheme: flatly\nimage: neiss.png\n---\n\n\n## Fine Tuning an LLM\n\nThis is part one of a two part blog series where I will be walking through the steps of building and evaluating a fine-tuned version of an LLM. I initially became interested in trying this, based on responses from other researchers claiming that cheap models could be fine-tuned for specific tasks and match or beat the performance of more expensive ones. In the real world, I see a lot of practical value. While more expenive models might give you better \"off the shelf\" performance, you might only need the LLM to complete a series of relatively simple tasks. Why not, instead, take a cheap model and train it on your specific task?\n\nWell, I thought I would give it a shot!\n\n## Setting up the Project\n\n### NEISS Injury and Product Narratives\n\nLet's start with straightforward task for the LLM. For this blog post I rely on the National Electronic Injury Surveillance System ([NEISS](https://www.cpsc.gov/Research--Statistics/NEISS-Injury-Data)) 2024 dataset. This data contains information about injuries reported to a representative sample of hospitals across the U.S. The data contains information about the person who was injured, including a short narrative from the hospital, which is useful for our purposes. The narratives look something like this:\n\n> 70YOM WAS DRINKING ALCOHOL AND TRIPPED AND FELL CAUSING HIS ARM TO GO THROUGH A GLASS WINDOW, DX: LT FOREARM LACERATION\n\nIn addition to the narratives, another set of fields are listings of various \"products\" that were related to the injury (`Product_1` to `Product_3`). These are referred to as the the \"external cause\" of the injury. The NEISS coding manualy provides the following definition as the \"external cause\":\n\n> ...the existence of a medical condition which can be associated with a specific object or acute process that was caused by something outside the body\n\nSo, for this specific example above, the product coded for this injury was `1894 - WINDOWS AND WINDOW GLASS, OTHER THAN STORM WINDOWS`. Here, the external cause is the glass that was broken by the patient's arm which caused a laceration to the forearm.\n\nSo how is the product chosen? Well, this can be a bit tricky. First off, the [NEISS coding manual](https://www.cpsc.gov/s3fs-public/January-2024-NEISS-CPSC-only-Coding-Manual.pdf?VersionId=bEaz2iKYDAlz8KA60KEKKrLrXZW3kLOj) contains over 800 different products. A small sampling shows:\n\n\n```         \n101 - WASHING MACHINES WITHOUT WRINGERS OR OTHER DRYERS\n102 - WRINGER WASHING MACHINES\n103 - WASHING MACHINES WITH UNHEATED SPIN DRYERS\n106 - ELECTRIC CLOTHES DRYERS WITHOUT WASHERS\n107 - GAS CLOTHES DRYERS WITHOUT WASHERS\n108 - MANGLE IRONS\n110 - ELECTRIC HEATING PADS\n112 - SEWING MACHINES OR ACCESSORIES\n113 - FLOOR BUFFERS OR WAXERS\n114 - RUG SHAMPOOERS\n115 - VACUUM CLEANERS\n116 - ELECTRIC BROOMS\n118 - GAS WATER HEATERS\n119 - ELECTRIC WATER HEATERS\n125 - WATER SOFTENERS OR CONDITIONERS (APPLIANCES)\n126 - WASHING MACHINES, NOT SPECIFIED\n127 - CLOTHES DRYERS, NOT SPECIFIED\n```\n\n### Identifying the \"external cause\"\n\nThe large variety of possible options highlights an interesting question. If we wanted an LLM to read the injury case narratives and tag each case with the appropriate product, how feasible would this be? Could we do it with a very cheap model? There are a few possible issues to consider here:\n\n1.  There are a very large number of possible products from which we can choose, but only one \"correct\" answer.\n\n2.  Many of the products are very subtly different from each other. For example, how do we easily distinguish between `610 - NONGLASS BATHTUBS OR SHOWERS` and `611 - BATHTUBS OR SHOWERS` (a bit of a hint for later)?\n\n3.  A narrative can have many products involved in an injury, but we have to choose the product that is *most related* to that injury.\n\nHere's a clearer way to illustrate the problem. Read this narrative below and guess which product was related to this injury. For simplicity I am narrowing it down to four options.\n\n> 64YOF, NINE DAYS AGO WAS STANDING ON A CHAIR HANGING HOLIDAY DECORATIONS WHEN SHE FELL ONTO LEFT HIP AND SINCE THEN HAS LOW BACK PAIN, DX: LOW BACK PAIN\n\na.  1714 - SEASONAL DECORATIONS\nb.  4074 - CHAIRS, OTHER OR NOT SPECIFIED\nc.  1807 - FLOORS OR FLOORING MATERIALS\nd.  4025 - BARSTOOLS OR KITCHEN STOOLS\n\n::: {.callout-tip collapse=\"true\"}\n## Answer\nThe answer is \"b\": 4074 - CHAIRS, OTHER OR NOT SPECIFIED\n:::\n\n## Labeling Narratives with ChatGPT\n\nTo start, I'll run quickly through my initial approach to this problem, using ChatGPT via the `OpenAI` python library. My idea is to do the following:\n\n1.  Construct a prompt that narrowly focuses the AI to identify the product that is *most proximate* to the injury\n2.  Use RAG to give the AI a narrower list of products to choose from\n3.  Review the results, then build a fine-tuned version of the model, based on steps 1&2.\n\nToday we'll focus just on the first two steps, before we get into fine tuning. I'll walk through a few key functions in my code, but if you want to look at the whole setup, you can just navigate to the working environment [on my repo](https://github.com/gmcirco/blog/tree/master/posts/uv-testing).\n\n### Parameters, Roles, and Prompts\n\nIn my `prepare_batch.py` file I first define some important parameters for setting up the RAG model, as well as defining the LLM's role:\n\n::: {#07d8d745 .cell execution_count=2}\n``` {.python .cell-code}\nRUN_DATE = datetime.now().strftime(\"%Y-%m-%d\")\nNUM_NARRATIVES = 500\nRAG_MODEL = SentenceTransformer(\"all-mpnet-base-v2\")\nMODEL = \"gpt-4o-mini\"\nROLE = \"\"\"You are an expert medical grader. Your goal is to read incident narratives and \nextract structured output based on the information available in the narrative field. Your\nPRIMARY GOAL is to determine the product that is MOST PROXIMATE to the injury reported in\nthe narrative. You MUST choose only from the provided list of products and return the \nEXACT product name and produce code in your answer.\n\"\"\"\n\n# define regex to extract the core narrative for RAG\nCORE_NARRATIVE_REGEX = re.compile(\"\\d{1,3}\\s?[A-Z]{2,4}[,]?\\s+(.*?)(?=\\s*DX:)\")\n\n# Load stopwords\nSTOPWORDS = set(stopwords.words(\"english\"))\n```\n:::\n\n\nHere, I set up a RAG model using sentence transformers, and choose a cheap model from [OpenAI's model library](https://platform.openai.com/docs/models). I choose the cheapest available model which is `gpt-4o-mini` (at a cost of a measley 15 cents per million tokens!). The system role I define instructs the LLM to find the injury that is \"most proximate\" to the injury reported in the narrative. Finally, I have some regex to extract out just the core narrative (excluding the injury description) to pass to the RAG model for retriving a list of possible products.\n\nI set up a bunch of helper functions (see the repo if you're interested), but the important one is the prompt creator. This function takes as input a text narrative from a single injury case, as well as the RAG that gives the LLM a list of possible products to choose.\n\n::: {#cd62ea31 .cell execution_count=3}\n``` {.python .cell-code}\ndef create_prompt(neiss_incident, neiss_product_codes):\n\n    prompt = f\"\"\"Closely follow the numbered instructions to perform your evaluation of the narrative.\n\n        ## NARRATIVE\n        1. Read the following injury report narrative:\n\n        {neiss_incident}\n\n        ## PRODUCT LIST\n\n        2. Review the following list of products to choose from:\n\n        Products are listed in the format [code] - [product]\n\n        {neiss_product_codes}\n\n        ## INSTRUCTIONS\n\n        3. Identify the primary injury listed in the narrative\n        4. Identify the product from the provided product list that is MOST PROXIMATE to the primary injury\n        5. Provide the name of the product AND the product code in your answer\n        6. Return your answer as a JSON object, following the format below EXACTLY:\n\n        {{\"primary_injury\": [injury], \"product\": [product], \"product_code\": [product_code]}}\n\n        5. Review the following examples and follow the format closely in your output.\n\n        ## EXAMPLE 1\n        '13YOM REPORTS HE WAS GETTING INTO THE SHOWER WHEN HE SLIPPED AND FELL ON HIS SIDE AND HEARD A POP IN HIS FOOT. DX ACHILLES TENDON INJURY'\n        {{\"primary_injury\": \"DX ACHILLES TENDON INJURY\", \"product\": \"BATHTUBS OR SHOWERS\", \"product_code\": 611}}\n\n        ## EXAMPLE 2\n        '36YOM REPORTS WITH KNEE PAIN AFTER FALLING OFF AN ELECTRIC SCOOTER. DX KNEE ABRASION'\n        {{\"primary_injury\": \"KNEE ABRASION\", \"product\": \"SCOOTERS, POWERED\", \"product_code\": 5022}}\n\n        ## EXAMPLE 3\n        '76YOF WAS WALKING INTO A BUILDING AND TRIPPED OVER A DOOR JAM AND FELL. PAIN TO HIPS, RIGHT KNEE AND RIGHT WRIST. DX: PAIN KNEE RIGHT, PAIN WRIST RIGHT, PAIN HIP LEFT'\n        {{\"primary_injury\": \"PAIN KNEE RIGHT, PAIN WRIST RIGHT, PAIN HIP LEFT\", \"product\": \"DOOR SILLS OR FRAMES\", \"product_code\": 1878}}\n\n        ## EXAMPLE 4\n        '67YOM FELL OUT OF CHAIR AND HAVING ALTERED MENTAL STATUS. DX FALL NO INJURY'\n        {{\"primary_injury\": \"FALL NO INJURY\", \"product\": \"CHAIRS, OTHER OR NOT SPECIFIED\", \"product_code\": 4074}}\n\n        ## EXAMPLE 5\n        '48YOM WAS ATTEMPTING TO GET OUT OF BED AND FELT VERY DIZZY AND FELL DX: CLOSED HEAD INJURY VERTIGO'\n        {{\"primary_injury\": \"CLOSED HEAD INJURY VERTIGO\", \"product\": \"BEDS OR BEDFRAMES, OTHER OR NOT SPECIFIED\", \"product_code\": 4076}}\n        \"\"\"\n\n    return prompt\n```\n:::\n\n\nThe actual prompt when it is populated with the narrative and the list of products from RAG looks like this:\n\n::: {#9bf52332 .cell execution_count=4}\n``` {.python .cell-code code-fold=\"true\"}\n\"\"\"\nClosely follow the numbered instructions to perform your evaluation of the narrative.\n\n        ## NARRATIVE\n        1. Read the following injury report narrative:\n\n        16YOM PLAYING SOCCER, HURT HIS SHOULDER.  HIT BY A BALL.DX:   MUSCLE STRAIN LEFT SHOULDER.\n\n        ## PRODUCT LIST\n\n        2. Review the following list of products to choose from:\n\n        Products are listed in the format [code] - [product]\n\n        1200 - Sports and recreational activity, not elsewhere classified\n        1205 - Basketball (activity, apparel or equipment)\n        1206 - Bowling (activity, apparel or equipment)\n        1211 - Football (activity, apparel or equipment)\n        1233 - Trampolines\n        1260 - Billiards or pool (activity, apparel or equipment)\n        1266 - Volleyball (activity, apparel or equipment)\n        1267 - Soccer (activity, apparel or equipment)\n        1282 - Handball (activity, apparel or equipment)\n        1295 - Field hockey (activity, apparel or equipment)\n        1326 - Blocks, stacking toys or pull toys\n        1333 - Skateboards\n        1346 - Clacker balls\n        1392 - Toy sports equipment\n        1513 - Playpens and play yards\n        1554 - Safety pins\n        3235 - Other ball sports (activity, apparel or equipment)\n        3236 - Ball sports (activity, apparel or equipment), not specified\n        3256 - Squash, racquet ball or paddle ball (activity, apparel or equipment)\n        3265 - Weight lifting (activity, apparel or equipment)\n        3272 - Hockey (activity, apparel or equipment), not specified\n        3276 - Water polo (activity, apparel or equipment)\n        3289 - Darts, for indoor use (activity or equipment)\n        3290 - Darts, lawn (activity or equipment)\n        3291 - Darts, not specified\n        5016 - Balls, other or not specified\n        5034 - Softball (activity, apparel or equipment)\n        5041 - Baseball (activity, apparel or equipment\n\n        ## INSTRUCTIONS\n\n        3. Identify the primary injury listed in the narrative\n        4. Identify the product from the provided product list that is MOST PROXIMATE to the primary injury\n        5. Provide the name of the product AND the product code in your answer\n        6. Return your answer as a JSON object, following the format below EXACTLY:\n\n        {\"primary_injury\": [injury], \"product\": [product], \"product_code\": [product_code]}\n\n        5. Review the following examples and follow the format closely in your output.\n\n        [examples omitted]\n\"\"\"\n```\n:::\n\n\nThe RAG model is configured to find fairly close matches based on the narrative, but give a up to 10 products per phrase match. The goal is to provide a wide variety of products that should be at least somewhat related to the narrative. This saves us a lot of tokens from not embedding the entire list of products (which is close to 9000 tokens), and helps our cheap model's performance by shortening the context window.\n\nAnd, finally, the output I expect to get is in json format:\n\n```\n'{\"primary_injury\": \"MUSCLE STRAIN LEFT SHOULDER\", \"product\": \"SOCCER (activity, apparel or equipment)\", \"product_code\": 1267}'\n```\n\n### Full workflow\n\nAll right, time for the full workflow. We first grab the top $N$ narratives from the NEISS csv (here, 500), load all of the product codes, and run these through the functions to extract the narrative, build the RAG, and pipe that into a prompt creation function wrapper `create_prompt_with_rag`. Then we simply loop over all the narratives, write them into a jsonlines file, and submit the whole batch to OpenAI.\n\n::: {#06b19a2a .cell execution_count=5}\n``` {.python .cell-code code-fold=\"true\"}\n# get NEISS narratives\nneiss_json = load_neiss_data(neiss_data, NUM_NARRATIVES)\nproduct_codes = load_product_codes(neiss_codes)\n\n# set up vector db for rag\nproducts = load_product_codes(neiss_codes)\n\n# Precompute product description embeddings\nproduct_texts = [p[\"product_title\"] for p in products]\nproduct_embeddings = RAG_MODEL.encode(product_texts, convert_to_tensor=True)\n\n# func to loop, add rag to prompt\ndef create_prompt_with_rag(neiss_json):\n    neiss_narrative = get_narrative(neiss_json)\n    neiss_product_narrative = extract_core_narrative(neiss_narrative)\n    phrases = extract_phrases(neiss_product_narrative)\n    codes = match_phrases_to_products(phrases, product_embeddings, product_codes)\n    code_str = extract_unique_matches_as_string(codes)\n    \n    return create_prompt(neiss_narrative, code_str)\n\n# now loop through whole process, fill up jsonl\njson_list = []\n\nfor narrative in neiss_json:\n    id = get_id(narrative)\n    prompt = create_prompt_with_rag(narrative)\n\n    json_list.append(\n        {\n            \"custom_id\": f\"{id}\",\n            \"method\": \"POST\",\n            \"url\": \"/v1/chat/completions\",\n            \"body\": {\n                \"model\": MODEL,\n                \"messages\": [\n                    {\"role\": \"system\", \"content\": ROLE},\n                    {\"role\": \"user\", \"content\": prompt},\n                ],\n                \"max_tokens\": 100,\n                \"temperature\": 0.1,\n                \"response_format\": {\"type\": \"json_object\"},\n            },\n        }\n    )\n\nwith open(f\"json/output_{RUN_DATE}.jsonl\", \"w\") as outfile:\n    for entry in json_list:\n        json.dump(entry, outfile)\n        outfile.write(\"\\n\")\n\n# upload batch to openai\nbatch_input_file = client.files.create(\n    file=open(f\"json/output_{RUN_DATE}.jsonl\", \"rb\"), purpose=\"batch\"\n)\n\nbatch_input_file_id = batch_input_file.id\nclient.batches.create(\n    input_file_id=batch_input_file_id,\n    endpoint=\"/v1/chat/completions\",\n    completion_window=\"24h\",\n    metadata={\"description\": f\"Testing {NUM_NARRATIVES} NEISS narratives\"},\n)\n```\n:::\n\n\n## Evaluation\n\nOf course, the major question is how did our cheap model do? To evaluate it, we need to load our batch output back in after it has been run through the OpenAI batch API. For simplicity I just convert it from a jsonlines file to a pandas dataframe. I also load in the original data as well from the NEISS table, as well as the original list of product codes. To keep this simple (I am just doing this for fun, on my own blog after all) I restrict the evaluation metrics to whether the LLM correctly identified any of the 3 possible products listed for an injury. This is more in line with how they are coded by humans. According to the NEISS coding manual:\n\n> When multiple products are involved, it does not matter in what order you enter them.\n\nSo, for our purposes, I'll be satisfied if the LLM's listed primary product lines up with *any* of the products in the data.\n\n::: {#9cfd1acc .cell execution_count=6}\n``` {.python .cell-code}\n# load the first 500 cases and product codes\nneiss_df = pd.read_csv(neiss_data).head(500)\nproduct_codes = load_product_codes(neiss_codes)\n\n\n# load output, set up vector database and original data\nfile = \"json/batch_682f2331c2fc81908ea42a70bf77709c_output.jsonl\"\njson_batch_output, narrative_ids = load_batch(file)\n\n# converting output to datafraames\nproduct_codes_df = pd.DataFrame(product_codes)\nproduct_codes_df['code'] = product_codes_df['code'].astype(int)\n\nneiss_df = neiss_df.merge(product_codes_df, how='left', left_on='Product_1', right_on='code') \\\n                   .rename(columns={'product_title': 'product_title_1'}) \\\n                   .merge(product_codes_df, how='left', left_on='Product_2', right_on='code') \\\n                   .rename(columns={'product_title': 'product_title_2'}) \\\n                   .merge(product_codes_df, how='left', left_on='Product_3', right_on='code') \\\n                   .rename(columns={'product_title': 'product_title_3'})\n\nneiss_df = neiss_df[[\n    'CPSC_Case_Number', 'Product_1', 'Product_2', 'Product_3',\n    'product_title_1', 'product_title_2', 'product_title_3', 'Narrative_1'\n]]\n\n# get llm output into a dataframe\nllm_output_dataframe = pd.DataFrame([json.loads(json_str) for json_str in json_batch_output])\nllm_output_dataframe['CPSC_Case_Number'] = list(map(int, narrative_ids))\n\n# Rename fields\nllm_output_dataframe = llm_output_dataframe.rename(columns={\n    'product': 'llm_product',\n    'product_code': 'llm_product_code'\n})\n\n# now flag, add a label for hit or miss\nllm_output_dataframe['label'] = (\n    (llm_output_dataframe['llm_product_code'] == neiss_df['Product_1'].astype(int)) |\n    (llm_output_dataframe['llm_product_code'] == neiss_df['Product_2'].astype(int)) |\n    (llm_output_dataframe['llm_product_code'] == neiss_df['Product_3'].astype(int))\n)\n\naccuracy = llm_output_dataframe['label'].mean()\n```\n:::\n\n\nHere's the LLM output in a pandas dataframe. I grab the LLM's primary injury, the product name, and the product code. I can then compare this to the original labels, keeping in mind that I'm only interested in the `Product_1` code.\n\n::: {#d8dbfbcc .cell execution_count=7}\n``` {.python .cell-code}\nprint(f'Accuracy: {accuracy:.2%}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 66.40%\n```\n:::\n:::\n\n\nAn initial accuracy here at about 66%. Not great, but not terrible for a first pass. This will be the baseline value I use before building out a fine-tuned model.\n\n### Digging a bit deeper\n\nSo one important thing to consider is where the model did well, and where it fell short. Before starting on any fine-tuning, it would be helpful to look for areas where there are obvious shortcomings and set up the LLM with examples to help guide it toward more \"correct\" answers.\n\nFirst, there are the original NEISS fields (`Narrative_1`, `Product_1`, `product_title_1`) merged with the LLM labeled ones (`product_code`, `product`), and a flag for whether the LLM's guess at the primary product was correct or not (`label`).\n\n::: {#5c4ad573 .cell .caption-undefined execution_count=8}\n``` {.python .cell-code code-fold=\"true\"}\n# merge and re-order\ncol_order = ['CPSC_Case_Number','Narrative_1', 'Product_1', 'Product_2', 'Product_3','product_title_1', 'llm_product_code', 'llm_product','label']\nllm_output_dataframe = llm_output_dataframe.merge(neiss_df, on = \"CPSC_Case_Number\")\nllm_output_dataframe = llm_output_dataframe[col_order]\nllm_output_dataframe.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CPSC_Case_Number</th>\n      <th>Narrative_1</th>\n      <th>Product_1</th>\n      <th>Product_2</th>\n      <th>Product_3</th>\n      <th>product_title_1</th>\n      <th>llm_product_code</th>\n      <th>llm_product</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>240108461</td>\n      <td>16YOM PLAYING SOCCER, HURT HIS SHOULDER.  HIT ...</td>\n      <td>1267</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Soccer (activity, apparel or equipment)</td>\n      <td>1267</td>\n      <td>SOCCER (activity, apparel or equipment)</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>240108462</td>\n      <td>56YOF WAS CUTTING UP CABBAGE AND KNIFE SLIPPED...</td>\n      <td>464</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Knives, not elsewhere classified</td>\n      <td>464</td>\n      <td>KNIVES, NOT ELSEWHERE CLASSIFIED</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>240109863</td>\n      <td>10 YOM C/O CRUSH INJURY OF TOE S/P RIDING A DI...</td>\n      <td>5036</td>\n      <td>1615</td>\n      <td>0</td>\n      <td>Two-wheeled, powered, off-road vehicles (incl....</td>\n      <td>1615</td>\n      <td>FOOTWEAR</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>240109864</td>\n      <td>3 YOF PRESENTS WITH SWALLOWED FOREIGN BODY S/P...</td>\n      <td>1686</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Coins</td>\n      <td>1686</td>\n      <td>COINS</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>240109865</td>\n      <td>2 YOM PRESENTS WITH FACIAL LACERATION S/P FELL...</td>\n      <td>4074</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chairs, other or not specified</td>\n      <td>6670</td>\n      <td>CHAIR, RECLINER</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n\nNEISS product codes and LLM-labeled product codes\n:::\n:::\n\n\nWith the data in this format, it's easy to explore a bit further. Here, I group up the products by the LLM's labeled product code, then get the proportion correct. As an example, 34 out of 34 times that the LLM guessed the product was `1807 FLOORS OR FLOORING MATERIALS` it got it correct, and 25 out of 26 times for `4076 BEDS OR BEDFRAMES, OTHER OR NOT SPECIFIED`. Among the top 5 products the results aren't too bad, although it misclassifies knives slightly more often.\n\n::: {#6cb8b65e .cell .caption-undefined execution_count=9}\n``` {.python .cell-code code-fold=\"true\"}\nllm_output_dataframe.groupby(['llm_product_code', 'llm_product']).agg(\n    label_mean=('label', 'mean'),\n    label_count=('label', 'count')\n).sort_values('label_count', ascending=False).head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>label_mean</th>\n      <th>label_count</th>\n    </tr>\n    <tr>\n      <th>llm_product_code</th>\n      <th>llm_product</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1807</th>\n      <th>FLOORS OR FLOORING MATERIALS</th>\n      <td>1.000000</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>4076</th>\n      <th>BEDS OR BEDFRAMES, OTHER OR NOT SPECIFIED</th>\n      <td>0.961538</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1842</th>\n      <th>STEPS OR STAIRS (EXCLUDING PULL-DOWN AND FOLDING STAIRS)</th>\n      <td>1.000000</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>464</th>\n      <th>KNIVES, NOT ELSEWHERE CLASSIFIED</th>\n      <td>0.733333</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <th>SOFAS, COUCHES, DAVENPORTS, DIVANS OR STUDIO COUCHES</th>\n      <td>1.000000</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n\nProportion correctly labeled, by NEISS product type\n:::\n:::\n\n\nPerhaps more importantly, I want to see the specific cases where the LLM is consistently getting it *wrong*. The following code produces all of the misses, and groups up the results by the NEISS label and the LLM label. This way I can quickly see what the LLM thought it was, versus what it really was.\n\n::: {#f2ef8b6d .cell .caption-undefined execution_count=10}\n``` {.python .cell-code code-fold=\"true\"}\nllm_output_dataframe[llm_output_dataframe['label'] == False].groupby(['Product_1', 'product_title_1', 'llm_product_code', 'llm_product']).agg(\n    label_mean=('label', 'mean'),\n    label_count=('label', 'count')\n).sort_values('label_count', ascending=False).head(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>label_mean</th>\n      <th>label_count</th>\n    </tr>\n    <tr>\n      <th>Product_1</th>\n      <th>product_title_1</th>\n      <th>llm_product_code</th>\n      <th>llm_product</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>611</th>\n      <th>Bathtubs or showers (including fixtures or accessories</th>\n      <th>610</th>\n      <th>NONGLASS BATHTUB OR SHOWER ENCLOSURES</th>\n      <td>0.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1616</th>\n      <th>Jewelry (excluding watches)</th>\n      <th>1617</th>\n      <th>EAR PROTECTION DEVICES</th>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1112</th>\n      <th>Metal containers (excluding aerosols, trash and gasoline cans)</th>\n      <th>453</th>\n      <th>CAN OPENERS, NOT SPECIFIED</th>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1616</th>\n      <th>Jewelry (excluding watches)</th>\n      <th>1643</th>\n      <th>KEYS, KEY RINGS OR KEY CHAINS</th>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">4074</th>\n      <th rowspan=\"2\" valign=\"top\">Chairs, other or not specified</th>\n      <th>667</th>\n      <th>CHAIR, RECLINER</th>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6670</th>\n      <th>CHAIR, RECLINER</th>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>836</th>\n      <th>Knives with replaceable blades</th>\n      <th>464</th>\n      <th>KNIVES, NOT ELSEWHERE CLASSIFIED</th>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1884</th>\n      <th>Ceilings and walls (interior part of completed structure)</th>\n      <th>1893</th>\n      <th>DOORS, OTHER OR NOT SPECIFIED</th>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1807</th>\n      <th rowspan=\"2\" valign=\"top\">Floors or flooring materials</th>\n      <th>676</th>\n      <th>RUGS OR CARPETS, NOT SPECIFIED</th>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4074</th>\n      <th>CHAIRS, OTHER OR NOT SPECIFIED</th>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n\nIncorrectly labeled products, NEISS vs LLM\n:::\n:::\n\n\nOne of the first big sets of misses here is related to `611 - BATHTUBS OR SHOWERS`. Here the LLM missed 7 times by incorrectly labeling the product `610 - 'NONGLASS BATHTUB OR SHOWER ENCLOSURES'`. This one, in my opinion, is really just an artifact of some rules coding in the manual. Personally, I don't see an easy way to distinguish the two - unless we assume that the \"enclosures\" part is just referring to the plastic partition that is often part of a shower.\n\nI also see some issues where the LLM picks ear protection devices instead of jewelry, metal containers instead of can openers, and recliner chairs instead of \"other or not specified\" chairs. An interesting issue crops up where the LLM labels `836 KNIVES WITH REPLACEABLE BLADES` as just `464 - KNIVES, NOT ELSEWHERE CLASSIFIED`. Reading through the narratives the former generally refers to things like box cutters, while the latter is typically *any* sort of knife (e.g. kitchen knife). There's also some evidence of hallucinations, like where the LLM is labeling `6670  CHAIR, RECLINER` instead of `667 CHAIR, RECLINER`.\n\n## Tasks for Fine Tuning\n\nReading through the results, I made myself some notes:\n\n::: {#2b0953ee .cell execution_count=11}\n``` {.python .cell-code}\n# model is having trouble with following:\n\n# 1 identifying 1616 - JEWELRY\n# 2 identifying 1884 - CEILINGS AND WALLS (INTERIOR PART OF COMPLETED STRUCTURE)\n# 3 marking 4074 - CHAIRS, OTHER OR NOT SPECIFIED as 670 - CHAIR, RECLINER\n# 4 marking 4076 - BEDS OR BEDFRAMES, OTHER OR NOT SPECIFIED as BUNK BEDS\n# 5 marking 1615 - FOOTWEAR in cases that involve injuries to foot\n# 6 cases involving drugs -> injury  (1929 DRUGS OR MEDICATIONS)\n# 7 610 - NONGLASS BATHTUBS OR SHOWERS versus 611 - BATHTUBS OR SHOWERS\n# 8 Some hallucinations (e.g. knife product code listed as 9464 instead of 464, 6670 versus 667)\n```\n:::\n\n\nOur next step, after assuming the RAG correctly provides the LLM with list of products that contains the correct one, is to fine-tune the model by feeding it examples it missed with the correct example. Ideally this will help guide the model toward the correct product, as well as help with hallucinating some product codes. In the next blog post I'll walk through how I created a curated list of examples and fed this through OpenAI's fine tuning API. We'll see if it made a big difference or not!\n\n",
    "supporting": [
      "fine-tuning_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}