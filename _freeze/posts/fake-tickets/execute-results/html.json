{
  "hash": "5d867b6837c229577677d281634916e0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Finding Fake Traffic Tickets in CT State Police Data\"\nsubtitle: \"A decidedly old-school approach\"\nauthor: Gio Circo, Ph.D.\ndate: 2025-3-07\ncategories:\n  - R\n  - Anomaly Detection\nformat: \n    html:\n        self-contained: true\n        code-fold: false\n        mainfont: \"Roboto\"\n        section-divs: true\n        toc: true\n        title-block-banner: true\n        mermaid:\n            theme: neutral\ntheme: flatly\n---\n\n\n\n\n\n\n## Fake Tickets Galore\n\nIn 2022 news broke that Connecticut State Police officers had been likely submitting tens of thousands of fake traffic tickets. What started from a [report by CT Insider](https://www.ctinsider.com/news/article/CT-troopers-fabricated-tickets-17393339.php) about 4 officers expanded to an audit that implicated dozens more officers in the scandal. \n\nBefore I start, this is more of an academic exercise. I actually think the approach that the folks who did the audit is probably the best way and simplest way. In their case they found fake tickets by counting up the number of stops which didn't have a matching citation in the system. For this example we're going to rely only on the raw data which is publically available.\n\n## Working on the outside\n\nMy hypothesis for the fake ticketing was that officers wanted to quickly pad their activity logs with fake stops. Because creating a stop log requires filling out a standardized form, I assumed that these officers would do it as quickly and as lazily as possible. I can imagine this looking like an officer at the end of their shift padding out activity with a bunch of zero-effort fake stops. Relying on this hunch, I figured I could detect unusual officer behavior by finding those whose distribution of stop times looked much different than the average officer. Humans are actually [quite bad](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041531) at generating \"random\" numbers. In order to pad out a shift, there would probably be a lot of stops with very short times.\n\n### The Data\n\nThe data for this comes from Connecticut's [Racial Profiling Prohibition Project](http://trafficstops.ctdata.org/) data portal. These contain data on all traffic stops conducted by local and state police, which have information on the time, date, reason for the stop, and some basic demographic information on the driver. For this analysis I use the data from 2018, and focus on unique stops involving only officers from the Connecticut State Police. \n\nUnfortunately for me, the publicly available data doesn't directly disclose the length of the stop. There is a variable `InterventionDurationCode` which only reports the length of the stop between 3 bins: `(0-15, 16-30, 30+)`. For my purposes this is far too coarse of a measure to distinguish abnormal stop lengths. However, as an analog, I figured I could instead compute the time interval *between* stops. That is, the interval in time between when one stop begins and the next stop begins. This gives us an indirect way of measuring how long a stop took before the next stop was initiated:\n\n$$interval= time_{stop2} - time_{stop_1}$$\n\nSo if we had two stops, with one at `16:31:31` and one at `16:40:15`, the *interval* would be about 8.7 minutes. As an example, this would look like:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n          ID       Troop Violation_Type       Date     Time Duration Interval\n1 1000001884 CSP Troop E  STC Violation 2018-01-07 16:31:31     <NA>       NA\n2 1000001884 CSP Troop E  Speed Related 2018-01-07 16:40:15 524 secs 8.733333\n```\n\n\n:::\n:::\n\n\n\n## Results\n\nTo start, it makes sense to first evaluate what \"average\" stop length intervals look like. One way of doing this is just a bunch of density plots for each officer. Here we're looking at the top 100 officers by number of stops for 2018. The dark line here is the average for all 100 officers. We can see that the majority of stop intervals are between 10 and 20 minutes, with a long tail reaching out to our maximum of 1 hour. This makes sense, because most traffic stops are pretty perfunctory: warning drivers that a tail light is out, writing a ticket for speeding, etc...). However, a small number of traffic stops are more complex and might involve searches, DWI investigations, or require another officer to attend. Regardless, this plot below gives us some idea of the \"average\" stop time, as well as the individual behaviors of different officers.  \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](fake-tickets_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nBut I think an easier way to visualize this is to transform the distribution above to the *empirical cumulative density function* (ECDF) for each officer. The ECDF is actually a very useful tool for this kind of question because it makes no assumptions about the distribution of the data. Simply put, and ECDF reports the proportion of observations at or below each given interval between $[0,1]$. All we do is report the cumulative value $1/n$ for each of the $n$ data points in a distribution. This is closely related to the quantile. Such that the ECDF at 0.5 is equivalent to the median. \n\nThe plot below shows the distribution of stop time intervals for all intervals between 0 and 60 minutes. The dark line is the average for all 100 officers, and the light colored lines are the individual officers' ECDFs. Below we see that the  median interval between stops is about 18 minutes. As we expect officer stop intervals are mostly randomly distributed above and below this. What we are actually interested in are officers whose ECDFs are unusually shorter compared to everyone else.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# plot all ecdfs \necdf_plot(id = unique(daily_stop_interval$officer_id),\n          lwd = 3,\n          main = \"Empirical CDF, Time Interval Between Stops\",\n          xlab = \"Interval Time (minutes)\",\n          ylab = \"Percentiles\",\n          col = \"#004488\")\nfor(id in times$officer_id){\n  ecdf_plot(id, lines=TRUE,col = alpha(rgb(0, .267, .533), .1))\n}\n```\n\n::: {.cell-output-display}\n![Among stop intervals under 60 minutes the median stop interval was 14 minutes. Under 10% of stops had intervals less than 6.5 minutes.](fake-tickets_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n### Intervals\n\nTo get intervals we do X:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute bands on all ecdfs, for 100 points\ntime_min <- min(daily_stop_interval$time_diff_min)\ntime_max <- max(daily_stop_interval$time_diff_min)\nN_points <- 125\n\nx_vals <- seq(time_min, time_max, length.out = N_points)\n\n\n# Compute all ECDF values at each x for all officer IDs\necdf_values <- sapply(times$officer_id, function(id) {\n  ecdf_func <- ecdf(daily_stop_interval$time_diff_min[daily_stop_interval$officer_id == id])\n  ecdf_func(x_vals)  \n})\n\n\n# Compute 5th and 95th percentiles for the confidence bands\nlower_band <- apply(ecdf_values, 1, function(row) quantile(row, 0.05))\nupper_band <- apply(ecdf_values, 1, function(row) quantile(row, 0.95))\n```\n:::\n\n\n\n\n### Officer \"88185785\"\n\nThis officer had the shortest average interval between stops at 14.2 minutes. In fact, more than half of their stops were at intervals of 10 minutes or less. This feels incredibly fast if you consider how long it takes to pull someone over. It seems implausible that this person was conducting almost non-stop traffic stops, taking driver information, issuing a warning (I assume?), and then getting *another* stop almost immediately afterwards. \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nofficer_id = '88185785'\n\n# Add confidence bands (shaded region)\nplot.new()\nplot(c(0, 60), c(0,1), col = \"white\", \n     main = \"Empirical CDF, Time Interval Between Stops\",\n     xlab = \"Interval Time (minutes)\",\n     ylab = \"Percentiles\")\npolygon(c(x_vals, rev(x_vals)), c(lower_band, rev(upper_band)), \n        col = rgb(0, .267, .533, 0.3), border = NA)\nlines(x_vals, lower_band, col = \"#004488\", lwd = 2, lty = 3)\nlines(x_vals, upper_band, col = \"#004488\", lwd = 2, lty = 3)\necdf_plot(officer_id, col = '#BB5566', lwd=2, lines = T)\n```\n\n::: {.cell-output-display}\n![](fake-tickets_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "fake-tickets_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}