{
  "hash": "fabcbe3cffa58f453af68f469e16fdef",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Information Retrieval Using the Retrieve and Rerank Method\"\nsubtitle: \"Extracting injury narratives from the NEISS\"\nauthor: Gio Circo, Ph.D.\ndate: 2025-1-24\ncategories:\n  - Python\n  - Data Science Applications\nformat: \n    html:\n        self-contained: true\n        code-fold: false\n        mainfont: \"Roboto\"\n        section-divs: true\n        toc: true\n        title-block-banner: true\n        mermaid:\n            theme: neutral\ntheme: flatly\nimage: words2.png\n---\n\n\n## Querying Records \n\n### Retrieve and rerank\n\nThe logic behind the \"[retrieve and rerank](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00473/110994/Retrieve-Fast-Rerank-Smart-Cooperative-and-Joint)\" method is that we have two sets of tools that excel at one specific task. Specifically we want to use a combination of a bi-encoder and cross-encoder to retrieve data based on an initial input query. The trade-off we have to deal with is that cross-enocder models are very slow, while bi-encoder models have performance that often falls short for retreval purposes.\n\nThe bi-encoder model (the \"retrieve\" part) creates seperate embeddings of the input query and corpus text and looks for the closest match based on the vector space. This is often done by finding the nearest cosine similarity. The retreval step is typically quite fast, with the trade-off that some information is lost because the query and search corpus are embedded seperately.\n\nOn the flip side, a cross encoder embeds the search query and corpus together. The major advantage of this, is that the cross-encoder uses cross-attention to create the similarity score, which pools information about the both inputs directly. However, the major trade off is that this requires the search query to be embedded with every query-corpus pair. In a very large dataset, this might create millions of pairs and is can be potentially very slow.\n\n#### Bi-encoder\n\n\n```{mermaid}\nflowchart LR\n  A(\"Sentence A\") ==> BA ==> SA ==> C\n  B(\"Sentence B\") ==> BB ==> SB ==> C\n  BA[\"BERT\"]\n  BB[\"BERT\"]\n  SA[\"Sentence Embedding\"]\n  SB[\"Sentence Embedding\"]\n  C[\"Cosine Similarity\"]\n```\n\n\n#### Cross-encoder\n\n\n```{mermaid}\nflowchart LR\n  A(\"Sentence A\") ==> C\n  B(\"Sentence A\") ==> C\n  C[\"BERT\"] ==> D\n  D[\"Classifier\"] ==> E  \n  E[\"0...1\"]\n```\n\n\nTherefore, it makes sense to use both of these methods in tandem. We can quickly retrieve the top 100 or so records using the bi-encoder, then re-rank the retrieved records using the bi-encoder. This way we limit the number of paired records we have to run through it. \n\nTo do this in Python I create a `RetrieveReranker` class. The class is initialized with a bi-encoder and cross-encoder model, and a corpus of text to serve as the searchable data base. Most of the important work is handled by the `query` function, which takes an input query string, creates an embedding, then retrieves the 100 most similar documents based on cosine similarity. These 100 records are then passed to the bi-encoder which re-ranks them and returns the most similar ones.\n\nI should note, this is a pretty limited first attempt at \"off-the-shelf\" pre-trained models. I'm not doing any pre-training, nor am I doing any fine-tuning here. It's quite clear that both would strongly improve performance, but this is too simple of an example to warrant the effort.\n\n::: {#2341b1f1 .cell message='false' execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport torch\nimport numpy as np\nimport os\nimport pickle\n\n\nclass RetrieveReranker:\n    def __init__(\n        self,\n        corpus,\n        bi_encoder_model,\n        cross_encoder_model,\n        save_corpus=False,\n        corpus_path=None,\n    ):\n        self.bi_encoder_model = bi_encoder_model\n        self.cross_encoder_model = cross_encoder_model\n        self.save_corpus = save_corpus\n        self.corpus_path = corpus_path\n\n        self.corpus = corpus  # raw text\n        self.corpus_embed = self._embed_corpus()  # embedded text\n\n    def _embed_corpus(self):\n        \"Embed and save a corpus of searchable text, or load corpus if present\"\n        embedding = None\n\n        try:\n            if os.path.exists(self.corpus_path):\n                embedding = self._load_corpus()\n            else:\n                embedding = self.bi_encoder_model.encode(self.corpus)\n\n                if self.save_corpus:\n                    self._save_corpus(embedding)\n\n        except Exception as e:\n            print(f\"Error processing corpus: {e}\")\n\n        return embedding\n\n    def _save_corpus(self, embedding):\n        with open(self.corpus_path, \"wb\") as fOut:\n            pickle.dump(embedding, fOut)\n\n    def _load_corpus(self):\n        with open(self.corpus_path, \"rb\") as fIn:\n            return pickle.load(fIn)\n\n    def query(self, query_string, number_ranks=100, number_results=1):\n        \"\"\"Find the top N results matching the input string and returning the\n        matched string and the index.\"\"\"\n\n        ce_list = []\n\n        # embed query in bi-enocder, then get cosine similarities w/ corpus\n        query_embed = self.bi_encoder_model.encode(query_string)\n        sims = self.bi_encoder_model.similarity(query_embed, self.corpus_embed)\n        idx = np.array(torch.topk(sims, number_ranks).indices)[0]\n\n        # create a list of paired strings\n        for i in idx:\n            ce_list.append([query_string, self.corpus[i]])\n\n        # run cross-encoder, get top `number_results`\n        # convert to probabilities using invlogit\n        scores = self.cross_encoder_model.predict(ce_list)\n        probs = torch.sigmoid(torch.tensor(scores))\n        top_idx = np.argsort(scores)[-number_results:][::-1]\n            \n        # Retrieve the results based on top indices\n        res_idx = [int(idx[i]) for i in top_idx] \n        res_prb = torch.tensor([probs[i] for i in top_idx])\n        res_str = [ce_list[i][1] for i in top_idx] \n\n        return res_idx, res_prb, res_str \n```\n:::\n\n\n## Creating A Records Retrieval Model\n\nNow that we have our class defined, we can import it below and utilize it. In order for it to work we need to pass in both a bi-encoder and a cross-encoder model. Recall, the bi-encoder will do the first pass to get the $N$ most similar records, then pass these to the cross-encoder. Hence, the \"retrieve and rerank\" method. Below, we use [ModernBERT](https://huggingface.co/docs/transformers/main/en/model_doc/modernbert) in tandem with a [SentenceTransformers](https://www.sbert.net/) model to do the embedding and first pass as the bi-encoder, and a [MS Macro](https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-12-v2) model as the cross encoder. \n\nNow, ideally we would fine-tune the cross-encoder model so that input queries would more closely match the medical narratives. This would have the added benefit of improvement performance for asymmeterical queries (e.g. providing a short query to retrieve a much longer text). But right now we can rely on out-of-the box performance as a demonstration.\n\nOur corpus is relatively small. We take a sample of 50,000 records from the [2022 NEISS](https://www.cpsc.gov/cgibin/NEISSQuery/home.aspx) dataset and use some local functions to clean up the NEISS text entries a bit before we pass them into the model. From these narratives we pass them through a SentenceTransformer model using ModernBert to embed them as a 50000x768 dimension array. Essentially this a fancy method of data compression, where we extract and store semantic meaning from the narratives as a vector of numeric values.\n\n::: {#4e98b3ee .cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\"}\nfrom sentence_transformers import SentenceTransformer\nfrom sentence_transformers.cross_encoder import CrossEncoder\n\nimport numpy as np\nimport pandas as pd\nimport re\n\nfrom src.search_funcs import RetrieveReranker\n\n# local vars\nBI_ENCODER_MODEL = \"answerdotai/ModernBERT-base\"\nCROSS_ENCODER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-12-v2\"\nCORPUS = \"C:/Users/gioc4/Documents/blog/data/falls/neis.csv\"\nCORPUS_SIZE = 50000\n\n# we want the observations to be agnostic to patient age, so we remove those\n# define remappings of abbreviations\n# and strings to remove from narratives\n\nremap = {\n    \"FX\": \"FRACTURE\",\n    \"INJ\": \"INJURY\",\n    \"LAC\": \"LACERATION\",\n    \"LOC\": \"LOSS OF CONCIOUSNESS\",\n    \"CONT\": \"CONTUSION\",\n    \"CHI\" : \"CLOSED HEAD INJURY\",\n    \"ETOH\": \"ALCOHOL\",\n    \"SDH\": \"SUBDURAL HEMATOMA\",\n    \"AFIB\": \"ATRIAL FIBRILLATION\",\n    \"NH\": \"NURSING HOME\",\n    \"LTCF\": \"LONG TERM CARE FACILITY\",\n    \"C/O\": \"COMPLAINS OF\",\n    \"H/O\": \"HISTORY OF\",\n    \"S/P\": \"STATUS POST\",\n    \"DX:\": \"DIAGNOSIS\",\n    \"YOM\": \"YEAR OLD MALE\",\n    \"YOF\": \"YEAR OLD FEMALE\",\n    \"MOM\": \"MONTH OLD MALE\",\n    \"MOF\": \"MONTH OLD FEMALE\",\n    \"PT\": \"PATIENT\",\n    \"LT\": \"LEFT\",\n    \"RT\": \"RIGHT\",\n    \"&\" : \" AND \"\n}\n\ndef process_text(txt):\n\n    # remap leading age and sex info\n    txt = re.sub(r\"(\\d+)(YOM|YOF|MOM|MOF)\", lambda m: f\"{m.group(1)} {remap[m.group(2)]}\", txt)\n\n    words = txt.split()\n    new_words = [remap.get(word, word) for word in words]\n    txt = \" \".join(new_words)\n\n    return re.sub(r\"^\\s+\", \"\", txt)\n```\n:::\n\n\nNow that we're ready, we can encode the corpus using the pre-defined models by passing it all into our `RetrieveReranker` class. Passing the corpus_path argument allows us to save the embeddings as a pickle file and reload it when it exists so we don't have to go through the very time consuming process of re-embedding the corpus each time we do this. Without using a GPU embedding 50,000 narratives takes around 30-40 minutes.\n\n::: {#0162ab79 .cell message='false' execution_count=3}\n``` {.python .cell-code}\n# strings to encode as searchable\n# load data\nneis_data = pd.read_csv(CORPUS).head(CORPUS_SIZE)\nnarrative_strings = neis_data['Narrative_1'].apply(process_text).tolist()\n\n# define models and ranker\nbiencoder = SentenceTransformer(BI_ENCODER_MODEL)\ncrossencoder = CrossEncoder(CROSS_ENCODER_MODEL)\n\n# set up a Retriveal-Ranker class\nranker = RetrieveReranker(\n    corpus=narrative_strings,\n    bi_encoder_model=biencoder,\n    cross_encoder_model=crossencoder,\n    save_corpus=True,\n    corpus_path=\"C:/Users/gioc4/Documents/blog/data/corpus_large.pkl\"\n)\n```\n:::\n\n\n### Retreiving similar records\n\nAfter that has processed we're ready to query our corpus with an example text string. Let's imagine we had a case involving an elderly fall at an elderly care facility (ECF) and we wanted to find 5 similar cases based on information provided in the narrative:\n\n> \"100 YOM RESIDENT AT ECF FELL BACKWARDS ON THE FLOOR. DX: CERVICAL STRAIN, LUMBAR STRAIN\"\n\nWe directly pass this query into our fitted `RetrieveReranker` and specify the number of results we want. We get indices and matching strings as output.\n\n::: {#517b336e .cell execution_count=4}\n``` {.python .cell-code}\nquery = \"100 YOM RESIDENT AT ECF FELL BACKWARDS ON THE FLOOR. DX: CERVICAL STRAIN, LUMBAR STRAIN\"\n\nidx, proba, output = ranker.query(process_text(query), number_results=5)\n```\n:::\n\n\nHere are the matching queries:\n\n::: {#8da94bcb .cell execution_count=5}\n``` {.python .cell-code}\noutput\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n['93 YEAR OLD FEMALE RESIDENT AT ECF LOST BALANCE AND FELL BACKWARDS ONTO THE FLOOR. DIAGNOSIS C-5 FRACTURE.',\n '87 YEAR OLD FEMALE RESIDENT AT ECF LOST BALANCE AND FELL BACKWARDS ON THE FLOOR. DIAGNOSIS SACRAL FRACTURE.',\n '84 YEAR OLD MALE RESIDENT AT ECF FELL ON THE FLOOR. DIAGNOSIS SUBDURAL HEMATOMA.',\n '71 YEAR OLD MALE RESIDENT AT ECF TRIPPED AND FELL ON THE FLOOR. DIAGNOSIS NASAL BONE FRACTURE.',\n '95 YEAR OLD FEMALE RESIDENT AT ECF FELL ON THE FLOOR. DIAGNOSIS CLOSED HEAD INJURY, LUMBAR STRAIN.']\n```\n:::\n:::\n\n\nThe probability scores:\n\n::: {#7f80386e .cell execution_count=6}\n``` {.python .cell-code}\nproba\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\ntensor([0.9996, 0.9996, 0.9996, 0.9995, 0.9995])\n```\n:::\n:::\n\n\nAnd are the matching records in the data frame:\n\n::: {#57c1686a .cell execution_count=7}\n``` {.python .cell-code}\nneis_data.iloc[idx]\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CPSC_Case_Number</th>\n      <th>Treatment_Date</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>Race</th>\n      <th>Other_Race</th>\n      <th>Hispanic</th>\n      <th>Body_Part</th>\n      <th>Diagnosis</th>\n      <th>Other_Diagnosis</th>\n      <th>...</th>\n      <th>Fire_Involvement</th>\n      <th>Product_1</th>\n      <th>Product_2</th>\n      <th>Product_3</th>\n      <th>Alcohol</th>\n      <th>Drug</th>\n      <th>Narrative_1</th>\n      <th>Stratum</th>\n      <th>PSU</th>\n      <th>Weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>47104</th>\n      <td>220505213</td>\n      <td>2/24/2022</td>\n      <td>93</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>89</td>\n      <td>57</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1807</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93 YOF RESIDENT AT ECF LOST BALANCE AND FELL B...</td>\n      <td>V</td>\n      <td>95</td>\n      <td>17.2223</td>\n    </tr>\n    <tr>\n      <th>46029</th>\n      <td>220410468</td>\n      <td>2/6/2022</td>\n      <td>87</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>79</td>\n      <td>57</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1807</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>87 YOF RESIDENT AT ECF LOST BALANCE AND FELL B...</td>\n      <td>V</td>\n      <td>95</td>\n      <td>17.2223</td>\n    </tr>\n    <tr>\n      <th>22886</th>\n      <td>220371574</td>\n      <td>1/28/2022</td>\n      <td>84</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>75</td>\n      <td>62</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1807</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>84 YOM RESIDENT AT ECF FELL ON THE FLOOR. DX: ...</td>\n      <td>V</td>\n      <td>95</td>\n      <td>17.2223</td>\n    </tr>\n    <tr>\n      <th>47110</th>\n      <td>220505221</td>\n      <td>2/24/2022</td>\n      <td>71</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>76</td>\n      <td>57</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1807</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>71 YOM RESIDENT AT ECF TRIPPED AND FELL ON THE...</td>\n      <td>V</td>\n      <td>95</td>\n      <td>17.2223</td>\n    </tr>\n    <tr>\n      <th>46661</th>\n      <td>220432778</td>\n      <td>2/12/2022</td>\n      <td>95</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>75</td>\n      <td>62</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1807</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>95 YOF RESIDENT AT ECF FELL ON THE FLOOR. DX: ...</td>\n      <td>V</td>\n      <td>95</td>\n      <td>17.2223</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>\n```\n:::\n:::\n\n\n### Asymmetrical queries\n\nGiven we have done zero fine tuning on either the embedding model or the cross encoder, the results are are pretty good. However, a notable weakness of this current approach is that the model is not robust for asymmetrical queries - that is, queries which are much shorter than the optimal one in the corpus. For example, let's say we just wanted to find a case where an elderly person fell in a bathtub. Here I just type in a manual example:\n\n::: {#35065ca7 .cell execution_count=8}\n``` {.python .cell-code}\nshort_query = \"80YOM SLIPPED AND FELL IN BATHTUB\"\n\n_, _, output = ranker.query(process_text(short_query ), number_results=5)\n\noutput\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n['16 YEAR OLD MALE SLIPPED AND FELL GETTING OUT OF BATHTUB. DX CONCUSSION',\n '30 YEAR OLD MALE FELL IN BATHTUB DX; BACK CONTUSION',\n '62 YEAR OLD MALE SLIPPED AND FELL IN THE SHOWER. DX:CERVICAL STRAIN.',\n '61 YEAR OLD MALE SLIPPED AND FELL GETTING OUT OF SHOWER DX; R ANKLE FRACTURE',\n '71 YEAR OLD MALE FELL IN SHOWER DX NECK PAIN']\n```\n:::\n:::\n\n\nThe results here are ok (they give us cases involving slip and falls in a bathtub) but we'll note they are similarly short to the input query. For example, here is another narrative involving an elderly fall in the bathtub, but it is ranked much lower because its length and structure are asymmetrical to the input:\n\n>\"75YOM    PT HAULING FIREWOOD 3 WKS AGO; DEVELOPED BACK PAIN.  2 NIGHTS AGO SLIPPED & FELL IN BATHTUB, COULDLN'T GET UP UNTIL MORNING WITH NEIGHBOR'S HELP     DX:  LOW BACK PAIN, SHINGLES, ELEVATED LIVER FUNCTION TESTS    #\"\n\n This is because the retreveal model matches close to queries with similar lengths. In the case of a true querying model, we need to map questions to positive and negative inputs. Fine-tuning the cross-encoder could help improve this, although it is a time-consuming process. What I wanted to demonstrate here is not a \"true\" RAG search model, but more of a semantic search and retreval model. In the latter approach the model expects to see a more context-rich example to use for document retreval. \n\n",
    "supporting": [
      "rank-rerank_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}