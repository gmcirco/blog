{
  "hash": "a2d14b706a08c97ea116b4a386fa7c3b",
  "result": {
    "markdown": "---\ntitle: \"Using NLP To Classify Medical Falls\"\nsubtitle: \"Or: An Old Dog Learning New Tricks\"\nauthor: Gio Circo, Ph.D.\ndate: 2024-1-8\ncategories:\n  - Natural Language Processing\n  - Python\nformat: \n    html:\n        self-contained: true\n        code-fold: false\n        mainfont: \"Roboto\"\n        section-divs: true\n        toc: true\n        title-block-banner: true\ntheme: flatly\nimage: words.jpg\n---\n\n## Natural Language Processing and Deep Learning\n\nThere's no question that natural language processing (NLP) facilitated by deep learning has exploded in popularity (much of which is popularized by the ChatGPT family of models). This is an exciting time to be involved in AI and machine learning. However, for the kinds of tasks I typically work on in my day job, a lot of the deep learning models don't provide much benefit. In fact, for most tabular data problems, random forests + boosting tend to work incredibly well. Areas where deep learning excels, like unstructured text or image input, are not things I find myself working on. That being said, I am always sharpening my skills and dipping my toes into areas where I am least familiar. \n\nA huge advantage today, compared to even ten years ago, is the ecosystem of open data and pre-trained models. [HuggingFace](https://huggingface.co/) in particular has a lot of easily obtainable pre-trained models. Stuff like the [Transformers](https://huggingface.co/docs/transformers/index) library make it easy for a neophyte like me to hop in and start doing work without too much overhead. \n\n## Predicting Elderly Falls from Medical Narratives\n\nFor this example I am going to rely on some data from [DrivenData](https://www.drivendata.org/competitions/217/cdc-fall-narratives/page/763/) - an organization that hosts data competitions. The data here are verified fall events for adults aged 65+. This sample comes more broadly from the [National Electronic Injury Survellience System](https://www.cpsc.gov/Research--Statistics/NEISS-Injury-Data)(NEISS). This is useful because the sample of cases here are human-verified falls cases, in which case we have a source of truth. While you could probably get pretty far just doing some regex like `str.match(\"FALL|FELL|SLIPPED\")` but it would likely miss more subtle cases. This is where having something like a BERT model is useful. \n\nLet's say we have a set of verified falls narratives (which we do) and we have a large set of miscellanous narratives that contain falls cases, as well as other injuries that are not falls. Our goal is to find narratives that are likely to be related to elderly fall cases. To do this, we will use the verified falls cases narratives from DataDriven as our \"training data\" so to speak, and we will use an NLP model to find cases that are semantically similar to these verified falls cases.\n\n### Data Setup\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport re\nfrom sentence_transformers import SentenceTransformer, util\n\nnp.random.seed(1)\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# load raw data\nfalls = pd.read_csv(\"../../../data/falls/falls.csv\")\nneis = pd.read_csv(\"../../../data/falls/neis.csv\")\n\n# process datetime\nfalls['treatment_date'] = pd.to_datetime(falls['treatment_date'])\n```\n:::\n\n\nTo get set up we read in the verified falls narratives, as well as the full sample of NEIS cases from 2022. After reading in our data we can perform some minor data cleaning to the narratives. Specifically, because we want to isolate narrative characterics associated with falls we should exclude the leading information about the patient's age and sex, as well as some other medical terminology. We can also remap some abbreviations to English and properly extract the actual age of the patient from the narrative. \n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# define remappings of abbreviations\n# and strings to remove from narratives\n\nremap = {\n    \"FX\": \"FRACTURE\",\n    \"INJ\": \"INJURY\",\n    \"LAC\": \"LACERATION\",\n    \"CONT\": \"CONTUSION\",\n    \"CHI\" : \"CLOSED HEAD INJURY\",\n    \"ETOH\": \"ALCOHOL\",\n    \"SDH\": \"SUBDURAL HEMATOMA\",\n    \"NH\": \"NURSING HOME\",\n    \"PT\": \"PATIENT\",\n    \"LT\": \"LEFT\",\n    \"RT\": \"RIGHT\",\n    \"&\" : \" AND \"\n}\nstr_remove = \"YOM|YOF|MOM|MOF|C/O|S/P|H/O|DX\"\n\n\ndef process_text(txt):\n    words = txt.split()\n    new_words = [remap.get(word, word) for word in words]\n    txt = \" \".join(new_words)\n\n    txt = re.sub(\"[^a-zA-Z ]\", \"\", txt)\n    txt = re.sub(str_remove, \"\", txt)\n\n    return re.sub(r\"^\\s+\", \"\", txt)\n\ndef narrative_age(string):\n    age = re.match(\"^\\d+\",string)\n\n    if not age:\n        age = 0\n    else:\n        age = age[0]\n        \n    return age\n```\n:::\n\n\nWe then apply these to our verified falls data and our raw NEIS data from 2022:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# process narrative text and extract patient age from narrative\nfalls['processed_narrative'] = falls['narrative'].apply(process_text)\nneis['processed_narrative'] = neis['Narrative_1'].apply(process_text)\n\nfalls['narrative_age'] = falls['narrative'].apply(narrative_age).astype(int)\nneis['narrative_age'] = neis['Narrative_1'].apply(narrative_age).astype(int)\n\n# neis cases are from 2022, remove from verified falls\nfalls = falls[falls['treatment_date'] < \"2022-01-01\"]\n\n# filter narrative ages to 65+\nfalls = falls[falls['narrative_age'] >= 65]\nneis = neis[neis['narrative_age'] >= 65]\n```\n:::\n\n\nWe can see that our coding changes the narratives subtly. For example this string:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfalls['narrative'][15]\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n'87YOF HAD A FALL TO THE FLOOR AT THE NH STRUCK BACK OF HEAD HEMATOMA TO SCALP'\n```\n:::\n:::\n\n\nIs changed to this:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfalls['processed_narrative'][15]\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n'HAD A FALL TO THE FLOOR AT THE NURSING HOME STRUCK BACK OF HEAD HEMATOMA TO SCALP'\n```\n:::\n:::\n\n\nThis minimal amount of pre-processing should help the model identify similar cases without being affected by too much extranenous information. In addition, because the typical model has about 30,000 words encoded we need to make sure we avoid abbreviations which will be absent from the model dictionary.\n\n### Implementing the Transformer model\n\nWe can grab all of our verified fall narratives as well as a random sample of narratives from the 2022 NEIS data. Below we'll take a sample of 250 cases and run them through our model.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nN = 250\nidx = np.random.choice(neis.shape[0], N, replace=False)\n\nfall_narrative = np.array(falls['processed_narrative'])\nneis_narrative = np.array(neis['processed_narrative'])[idx]\n```\n:::\n\n\nWe take the processed narratives and convert them to tokens using the pre-trained sentence transformer:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nembed_train = model.encode(fall_narrative)\nembed_test = model.encode(neis_narrative)\n```\n:::\n\n\nWe then compute the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) between the two tensors. What we will end up with is the distance from our NEIS narratives and the verified fall cases. Cases with larger distances should be less likely to contain information about elderly fall cases.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ncos_sim = util.cos_sim(embed_test, embed_train)\n```\n:::\n\n\nFor simplicity we scale the distances between 0 and 1, so that 1 is most similar and 0 is least similar. We can then just compare the rank-ordered narratives.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndists = cos_sim.mean(1)\nd_min, d_max = dists.min(), dists.max()\n\ndists = (dists - d_min)/(d_max - d_min)\ndists = np.array(dists)\n\nout = dict(zip(neis_narrative, dists)) \n```\n:::\n\n\nPlotting a histogram of the minmax scaled cosine similarity scores shows a lot of narratives that are very similar and a long tail of those that are not so similar. Of course, there isn't a single cut point of what we would consider acceptable for classification purposes, but we could certainly use these scores in a regression to determine a suitible cut point if we were so interested.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code code-fold=\"true\"}\ncparams = {\n    \"axes.spines.left\": False,\n    \"axes.spines.right\": False,\n    \"axes.spines.top\": False,\n    \"axes.spines.bottom\": False,\n    \"grid.linestyle\": \"--\"\n}\n\nsns.set_theme(style=\"ticks\", rc = cparams)\n\n(\n    sns.histplot(dists, color=\"#004488\"),\n    plt.xlabel(\"Cosine Similarity (minmax scaled)\")\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](nlp_falls_files/figure-html/cell-11-output-1.png){width=589 height=435}\n:::\n:::\n\n\n### Results\n\nTime to actually see the results. Our results are stored in a dictionary which allows us to just pull narratives by similarity score. Let's test it out by looking at the top 10 most similar NEIS narratives:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nsorted(out, key=out.get, reverse=True)[:10]\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n['FELL TO THE FLOOR AT THE NURSING HOME  CLOSED HEAD INJURY',\n 'FELL ON THE FLOOR  CLOSED HEAD INJURY',\n 'WAS AT THE NURSING HOME AND SLIPPED AND FELL TO THE FLOOR STRIKING HIS HEAD  SCALP LACERATION',\n 'PRESENTS AFTER A FALL WHILE WALKING ACROSS THE LIVING ROOM AND HE TRIPPED AND FELL TO THE FLOOR REPORTS HE HIT HIS HEAD AND LEFT SHOULDER ON A RUG  FALL CLOSED FRACTURE OF CERVICAL VERTEBRA',\n 'FELL TO THE FLOOR STRUCK HEAD  CLOSED HEAD INJURY ABRASION TO KNEES',\n 'WAS GETTING INTO BED AND FELL TO THE FLOOR ONTO HEAD  CLOSED HEAD INJURY',\n 'FELL ON FLOOR AT NH INJURY  AND  BODY PATIENT NS  FALL',\n 'FELL BACKWARDS FROM  STEPS CLOSED HEAD INJURY ABRASION HAND',\n 'PRESENTS WITH HEAD INJURY AFTER A FALL REPORTS HE WAS FOUND ON THE FLOOR IN A RESTAURANT AFTER HE SLIPPED AND FELL HITTING HIS HEAD  INJURY OF HEAD',\n 'WENT TO SIT DOWN AND SOMEONE MOVED HER CHAIR AND SHE FELL BACKWARDS HITTING HER HEAD ON THE FLOOR  FALL BLUNT HEAD TRAUMA TAIL BONE PAIN']\n```\n:::\n:::\n\n\nAnd the 10 *least* similar narratives:\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nsorted(out, key=out.get, reverse=False)[:10]\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n['SYNCOPAL EPISODE WHILE FOLDING NS CLOTHINGSYNCOPE',\n 'WAS COOKING SOME SALMON AND THEN SPRAYED A  AEROSOL DEODORANT DUE TO THE SMELL WHICH CAUSED HER TO FEEL THAT SOMETHING WAS STUCK IN HER THROAT FOREIGN BODY SENSATION IN THROAT',\n 'WAS PLAYING GOLF AND DEVELOPED AMS AND PASSED OUT  SYNCOPE',\n 'CO STABBING RIGHT CHEST PAIN RADIATES TO HER BACK SHORTNESS OF BREATH AFTER HER HHA WAS MOPPING THE FLOOR LAST NIGHT W STRONGPOTENT CLEANING AGENT THAT TRIGGERED HER ASTHMA  CHEST PAIN ASTHMA',\n 'WITH FISH HOOK IN HIS RIGHT INDEX FNIGER HAPPENED AT A LAKE FB RIGHT INDEX FINGER',\n 'CUT THUMB WITH BROKEN BOTTLE NO OTHER DETAILS LWOT NO ',\n 'EXERCISING FELT PAIN IN RIGHT LOWER LEG  LOWER LEG PAIN',\n 'CO LEFT SIDED CHEST PAIN FOR THE PAST THREE DAYS AFTER WORKING OUT AT THE GYM  LEFT PECTORALIS MUSCLE STRAIN',\n 'PRESENTS AFTER BEING IN A ROOM FILLED WITH SMOKE FOR  HOURS AFTER THERE WAS A FIRE IN HER NEIGHBORS APARTMENT UNKNOWN IF FIRE DEPARTMENT INVOLVED  SMOKE INHALATION PAIN IN THROAT ELEVATED TROPONIN',\n 'ON  FOR AF WAS WASHING DISHES AND SLASHED ARM ON A KNIFE  LACERATION OF RIGHT FOREARM']\n```\n:::\n:::\n\n\nSo in general, it did a pretty good job. The most similar cases are all clearly related to falls, while the least similar ones are all a mix of other injuries. While I don't have any tests here (coming soon!) I suspect this does better than very simple regex queries. If only because it has the ability to find similarities without needing to match on specific strings. \n\n## Singular Queries\n\nWe can extend this model a bit and create a small class object that will take a single query in, and return the $K$ most similar narratives. Below, we bundle our functions into a `NarrativeQuery` class object. After encoding the narrative we can provide query strings to find sementically similar narratives.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nclass NarrativeQuery:\n    def __init__(self, narrative):\n        self.narrative = narrative\n        self.narrative_embedding = None\n        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n    def encode(self):\n        self.narrative_embedding = self.model.encode(self.narrative)\n\n    def search_narrative(self, query, K = 5):\n        embed_query = self.model.encode(query)\n\n        query_out = self.cos_sim(self.narrative_embedding, embed_query)\n\n        return sorted(query_out, key=query_out.get, reverse=True)[:K]\n\n    def cos_sim(self, embed, embed_query):\n        cs = util.cos_sim(embed, embed_query)\n\n        dists = cs.mean(1)\n        d_min, d_max = dists.min(), dists.max()\n\n        dists = (dists - d_min)/(d_max - d_min)\n        dists = np.array(dists)\n\n        return dict(zip(self.narrative, dists))\n```\n:::\n\n\nThis sets it up:\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nFallsQuery = NarrativeQuery(neis_narrative)\nFallsQuery.encode()\n```\n:::\n\n\n...and this performs the search. Here we're just looking for narratives where a person slipped in a bathtub.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nFallsQuery.search_narrative(query=\"SLIPPED IN BATHTUB\", K = 10)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n['SLIPPED AND FELL IN THE SHOWER LANDING ONTO BUTTOCKS  CONTUSION TO BUTTOCKS',\n 'SLIPPED ON FLOOR AND FELL AT HOME  FALL',\n 'PRESENTS AFTER A SLIP AND FALL IN THE TUB STRIKING HER HEAD ON THE WALL  SYNCOPE FALL HEAD STRIKE',\n 'FELL IN THE SHOWER  FRACTURED UPPER BACK',\n 'PATIENT FELL IN THE SHOWER AND HIT HER HEAD AND HER LEFT ELBOW  LACERATION OF SCALP WITHOUT FOREIGN BODY STRUCK BATH TUB WITH FALL ABRASION OF LEFT ELBOW',\n 'WAS WALKING FROM THE BATHROOM TO THE BEDROOM AND PASSED OUT FALLING TO THE FLOOR CAUSING A SKIN TEAR TO HIS LEFT ELBOW  SKIN TEAR OF LEFT ELBOW',\n 'SLIPPED AND FELL IN FLOOR AT HOME  R HIP FRACTURE',\n 'FELL IN THE SHOWER AT HOME TWISTING RIGHT KNEE  RUPTURE RIGHT PATELAR TENDON',\n 'WEARING SOCKS SLIPPED AND FELLHEAD INJURYFX FEMUR',\n 'SLIPEPD AND FELL IN THE SHOWER STRUCK HEAD  CLOSED HEAD INJURY CONTUSION TO LEFT HIP']\n```\n:::\n:::\n\n\nNow *this* is cool. Using the sentence transformer we are able to get passages that are similar in style to what we searched, without sharing the exact same language. For example, the search query is `\"SLIPPED IN BATHTUB\"` but we get results like `\"FELL IN THE SHOWER\"` and `\"SLIP AND FALL IN THE TUB\"`. If we were looking specifically for passages related to falls in the bathtub these obviously make sense (many bathtubs are also just showers as well). \n\n## Finally\n\nNow, this isn't probably news to most people that actually regularly work with language models. However, it is quite impressive that with a pre-trained model and very minimal pre-processing, you can obtain reasonable results off-the-shelf. I'll definitely be keeping my eyes on these models in the future and looking for ways where they can improve my workflow.\n\n",
    "supporting": [
      "nlp_falls_files"
    ],
    "filters": [],
    "includes": {}
  }
}