{
  "hash": "2136a3df86b389feedc1d619dbb577b9",
  "result": {
    "markdown": "---\ntitle: \"Injuries at Amazon Warehouses - A Bayesian Approach\"\nauthor: \"Gio Circo, Ph.D\"\ndate: 2022-11-11\nformat: \n    html:\n        self-contained: true\n        code-fold: true\n        mainfont: \"Roboto\"\n        section-divs: true\n        toc: true\n        title-block-banner: true\ncategories:\n  - Bayesian Statistics\n  - HLM\ntheme: flatly\nbibliography: refs.bib\nimage: \"box.png\"\n---\n\n::: {.cell}\n\n:::\n\n\n## Injuries and Low Base Counts\n\nMy friend, Andy Wheeler, just recently posted on his blog about [reported injuries at Amazon warehouses](https://andrewpwheeler.com/2022/11/05/injury-rates-at-amazon-warehouses/). As he rightly points out, the apparent high number of injuries at these warehouses is primarily a function of the size of the locations. \n\nIn criminology we often deal with similar issues (namely, why we use crime *rates* rather than raw counts when comparing geographies of different populations). While I don't have much to add to Andy's post, one thing did stand out to me - the issue of low base counts.\n\n> But note that I don't think Bonded Logistics is a terribly dangerous place. One thing you need to watch out for when evaluating rate data is that places with smaller denominators (here lower total hours worked) tend to be more volatile.[@andrewwheeler2022]\n\nThis is also a very common problem across many different disciplines. Andrew Gelman discusses the problem in this paper about issues arising from [mapping county-level cancer rates](http://www.stat.columbia.edu/~gelman/research/published/allmaps.pdf). Similarly, he points out that very variable rates arise from very low sample sizes. For example: imagine a single murder occurs in the city of [Union, CT](https://www.city-data.com/city/Union-Connecticut.html). With a population of 854, that gives us a murder rate per 1,000 of $\\frac{1}{854} * 1,000 = 1.17$. This would potentially make it one of the highest-rate small towns in the state! Logically this doesn't make sense, because rare events can happen - but it doesn't imply a single region is especially unusual.\n\n![Counties with low population appear to have very high rates of kidney cancer. However, much of this is an illusion due to higher variance relative to higher population counties.](cancer.png)\n\n## Hierarchical Models\n\nAll of this discussion made me think about some issues I had addressed when studying crime - namely rare events (homicides or shootings) that are aggregated to small areas (census blocks or street segments). In these previous examples I had applied hierarchical models to help adjust for these issues we commonly observe with rare events. Let's work with the same data that Andy used in his example. First, we'll load the OSHA data for 2021 and isolate just the warehouses in North Carolina.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(knitr)\n\n# load osha data\nosha <- read_csv(unzip(\"C:/Users/gioc4/Dropbox/blogs/hlm_osha/ITA-data-cy2021.zip\"))\n\n# isolate NC injuries at warehouses\ninj_wh <- osha %>%\n  filter(naics_code == '493110',\n         state == 'NC') %>%\n  mutate(inj_rate = (total_injuries/total_hours_worked)*2080)\n```\n:::\n\n\nIf we plot the distribution of injury rates per-person work hour year we see that the majority of warehouses are quite low, and very few exceed 0.2. However on the far right we see a single extreme example - the outlier that is the Bonded Logistics warehouse.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code\"}\nggplot(inj_wh) +\n  geom_histogram(aes(x = inj_rate), \n                 fill = \"#004488\", \n                 color = \"white\",\n                 bins = 20,\n                 linewidth =1.5) +\n  labs(x = \"(total_injuries/total_hours_worked)*2080\", y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text = element_text(size = 12),\n        axis.title = element_text(face = \"bold\"))\n```\n\n::: {.cell-output-display}\n![](osha_shrinkage_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nSorting by the top 10 we see that Bonded Logistics has an injury rate nearly 4 times the next highest warehouse. But they also have only a single employee who worked 1,686 hours that year! Is this really a fair comparison? Following what we already know, almost certainly not.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code\"}\ninj_wh %>%\n  select(company_name, inj_rate, annual_average_employees, total_hours_worked) %>%\n  arrange(desc(inj_rate)) %>%\n  slice(1:10) %>%\n  kable(caption = \"Top 10 Warehouses, by Injury Rate\", \n        digits = 2,\n        col.names = c(\"Company\",\"Injury Rate\",\"Employees\",\"Total Hours Worked\"))\n```\n\n::: {.cell-output-display}\nTable: Top 10 Warehouses, by Injury Rate\n\n|Company                     | Injury Rate| Employees| Total Hours Worked|\n|:---------------------------|-----------:|---------:|------------------:|\n|Bonded Logistics            |        1.23|         1|               1686|\n|Technimark                  |        0.34|         4|               6154|\n|Bonded Logistics            |        0.30|         4|               6913|\n|CAPSTONE LOGISTICS, LLC     |        0.29|        36|              43137|\n|RH US LLC                   |        0.27|         7|               7703|\n|Aldi (N.C.) L.L.C.          |        0.22|       385|             569274|\n|Brame Specialty Company Inc |        0.17|         6|              12513|\n|Conn Appliances Inc         |        0.16|        15|              26634|\n|Blue Line Distribution      |        0.16|        31|              53287|\n|Tosca Services, LLC         |        0.16|        41|              66891|\n:::\n:::\n\n\nTo address this issue, we'll fit a (very) simple Bayesian hierarchical linear model where we give each warehouse its own intercept. We then partially pool estimates from the model toward the group-level means. In short, we'll model this as the number of injuries $y$ at each warehouse $j$ as a Poisson process, where each warehouse is modeled with its own (varying) intercept. In a minute we will see the advantage of this.\n\n$$y_{j} \\sim Poisson(\\lambda_{j})$$ $$ln(\\lambda{j}) = \\beta_{0j}$$\n\nUsing `brms` we'll fit a Poisson regression estimating the total number of injuries at any warehouse weighted by the logged number of hours worked. Because the model is extremely simple, we'll just keep the default priors with this model which are `student_t(3,0,3)`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit the hierarchical model w/ default priors\n\nfit <- brm(total_injuries ~ 1 + (1|id) + \n             offset(log(total_hours_worked)), \n           family = poisson(), \n           data = inj_wh,\n           file = \"C:/Users/gioc4/Dropbox/blogs/hlm_osha/brmfit\",\n           chains = 4, cores = 4, iter = 2000)\n```\n:::\n\n\nAfter the model fits, it's generally a good idea to make sure the predictions from the model correspond with the observed distribution of the data. Our posterior predictive checks show that we have fairly well captured the observed process, with our posterior simulations $\\hat{y}$ largely in line with the observed $y$.\n\n\n::: {.cell layout-nrow=\"1\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code\"}\npp_check(fit, \"hist\") + theme_bw()\n```\n\n::: {.cell-output-display}\n![](osha_shrinkage_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code\"}\npp_check(fit, \"scatter_avg\") + theme_bw()\n```\n\n::: {.cell-output-display}\n![](osha_shrinkage_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\n## Shrinkage!\n\nHere's where things get interesting. One of the benefits of a hierarchical model is that estimates from the model are partially pooled (shrunk) toward the group-level means. In a typical no-pooling model, estimates from very sparse clusters can be [extreme or even undefined](https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression). In our hierarchical example we are applying regularization to the estimates by trading higher *bias* for lower *variance*[@gelman1995bayesian]. In a Bayesian framework our application of a prior distribution helps set a reasonable boundary for our model estimates.\n\nTo illustrate this, we can see the difference between the predicted (blue circles) and observed (empty circles) below. For warehouses with very few worked hours we see that the estimates are pulled strongly toward the global mean. For warehouses with more hours, however, there is considerably less shrinkage.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code\"}\n# predicted vs actual\ninj_wh_pred <- inj_wh %>%\n  select(id, company_name, inj_rate, annual_average_employees, total_hours_worked) %>%\n  mutate(yhat = predict(fit, type = 'response')[,1],\n         inj_rate_pred = (yhat/total_hours_worked) * 2080)\n\n# Plot all values\nggplot(inj_wh_pred, aes(x = total_hours_worked)) +\n  geom_hline(yintercept = mean(inj_wh_pred$inj_rate), linewidth = 1, color = \"#004488\", alpha = .7)+\n  geom_point(aes(y = inj_rate), shape = 21, size = 2)+\n  geom_point(aes(y = inj_rate_pred), shape = 21, fill = \"#004488\", size = 2, alpha = .5) +\n  labs(x = \"Total Hours Worked\", y = \"Total Injuries/Hours Worked\") +\n  theme_minimal() +\n  theme(axis.text = element_text(size = 12),\n        axis.title = element_text(face = \"bold\"))\n```\n\n::: {.cell-output-display}\n![](osha_shrinkage_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nIf we constrain ourselves to the left-hand side of the plot we can view this even more clearly. The estimated value for the unusual Bonded Warehouse is `0.1` compared to the observed value of `1.23`. While this estimate is farther off from the observed value, it is probably much more reasonable based on the observed values of other warehouses.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code\"}\ninj_wh_pred %>%\n  filter(total_hours_worked < 1e5) %>%\n  ggplot(aes(x = total_hours_worked)) +\n  geom_hline(yintercept = mean(inj_wh_pred$inj_rate), linewidth = 1, color = \"#004488\", alpha = .7)+\n  geom_point(aes(y = inj_rate), shape = 21, size = 2)+\n  geom_point(aes(y = inj_rate_pred), shape = 21, fill = \"#004488\", size = 2, alpha = .5) +\n  labs(x = \"Total Hours Worked\", y = \"Total Injuries/Hours Worked\") +\n  theme_minimal() +\n  theme(axis.text = element_text(size = 12),\n        axis.title = element_text(face = \"bold\"))\n```\n\n::: {.cell-output-display}\n![](osha_shrinkage_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nIf we compare the predicted injury rates to the observed ones, we can see the differences in shrinkage as well. Larger warehouses have estimates quite close to the observed counts (like The Aldi warehouse which has a relatively high rate of injuries for its size).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninj_wh_pred %>%\n  select(company_name, inj_rate, inj_rate_pred, annual_average_employees, total_hours_worked) %>%\n  arrange(desc(inj_rate)) %>%\n  slice(1:10) %>%\n  kable(caption = \"Top 10 Warehouses, by Injury Rate\", \n        digits = 2,\n        col.names = c(\"Company\",\"Injury Rate\",\"(Pred) Injury Rate\", \"Employees\",\"Total Hours Worked\"))\n```\n\n::: {.cell-output-display}\nTable: Top 10 Warehouses, by Injury Rate\n\n|Company                     | Injury Rate| (Pred) Injury Rate| Employees| Total Hours Worked|\n|:---------------------------|-----------:|------------------:|---------:|------------------:|\n|Bonded Logistics            |        1.23|               0.10|         1|               1686|\n|Technimark                  |        0.34|               0.08|         4|               6154|\n|Bonded Logistics            |        0.30|               0.08|         4|               6913|\n|CAPSTONE LOGISTICS, LLC     |        0.29|               0.19|        36|              43137|\n|RH US LLC                   |        0.27|               0.07|         7|               7703|\n|Aldi (N.C.) L.L.C.          |        0.22|               0.21|       385|             569274|\n|Brame Specialty Company Inc |        0.17|               0.07|         6|              12513|\n|Conn Appliances Inc         |        0.16|               0.08|        15|              26634|\n|Blue Line Distribution      |        0.16|               0.10|        31|              53287|\n|Tosca Services, LLC         |        0.16|               0.11|        41|              66891|\n:::\n:::\n",
    "supporting": [
      "osha_shrinkage_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}