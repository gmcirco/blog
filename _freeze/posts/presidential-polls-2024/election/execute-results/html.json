{
  "hash": "976771d8da390806218a4309ae605a7f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"I Made An Election Model\"\nsubtitle: \"A (very, very late) discussion of election forecasting\"\nauthor: \"Gio Circo, Ph.D.\"\ndate: 2025-1-13\nformat: \n    html:\n        self-contained: false\n        code-fold: true\n        mainfont: \"Roboto\"\n        section-divs: true\n        toc: true\n        title-block-banner: true\ncategories:\n  - R\n  - Bayesian Statistics\ntheme: flatly\nimage: election.png\n---\n\n\n\n\n\n## Revisiting the 2024 Election\n\nThe 2024 election is over. Donald Trump beat Kamala Harris by about 2 million popular votes and 86 electoral votes. All the posturing, forecasting, and [betting](https://polymarket.com/elections) is over. So why am I posting about the election now?\n\nWell, at the outset of the election I became interesting in running my own forecasting model. Nowadays there are plenty of folks running their own forecasting models - from individual bloggers to big news agencies like the [New York Times](https://www.nytimes.com/interactive/2024/11/05/us/elections/results-president.html). Poll aggregation is one of those things that is very \"Bayesian\" and I learned a lot about it reading through various books. To boot, I've always been a big fan of Andrew Gelman, as well as some other folks who do election and public policy forecasting - like [Nate Silver](https://www.natesilver.net/) and [Elliot Morris](https://gelliottmorris.com/). So I thought, \"what the hell\" and threw my hat into the ring. I held off on posting this because I figured there was already enough noise out there about the election, and maybe the world didn't need one more person adding to the cacophony. \n\n## My Model\n\nTo keep it simple, I focused on the simplest kind of model - a poll aggregation model estimating national vote for the two-party candidates. This approach avoids a lot of additional complexity of estimating electoral college votes by not having to model state-level vote share, correlations between states, and many other things. This was truly just meant for a bit of academic fun. As a source of data, I used the very nicely curated tables supplied by [538 here](https://projects.fivethirtyeight.com/polls/national/), which was continuously updated during the election cycle. Helpfully, this data contains some other useful variables such as information about pollsters, and 538's own ranking of pollster's reliability. \n\nFor my model I applied filtering to get a subset of polls:\n\n- Only polls that included a Trump-Harris match up\n- Polls that were conducted just before Biden dropped out (6/1/2024)\n- Only polls including likely voters, registered voters, or adults\n- Removed overlapping polls\n- Polls with larger than 5,000 respondents\n\nDropping polls with more than 5,000 respondents is largely an approach to remove pollsters who \"dredge\" for lots of responses that are often typically of low quality. In total, this leaves us with about 255 unique polls in the 165 days between 6/1/2024 and 11/4/2024. \n\n### The poll aggregation approach\n\nFor the modelling approach I drew some inspiration from [Andrew Gelman](http://www.stat.columbia.edu/~gelman/research/published/hdsr_forecasting.pdf) and others. Most of the current poll aggregation models apply some form of hierarchical linear modelling (HLM), combined with time trends, and often a [\"fundamentals\" component](https://www.researchgate.net/profile/Alan-Abramowitz-4/publication/248650179_Forecasting_the_2008_Presidential_Election_with_the_Time-for-Change_Model/links/5613dc3808aec622440fd509/Forecasting-the-2008-Presidential-Election-with-the-Time-for-Change-Model.pdf). The general idea here is to partially pool information from many different pollsters, who are all utilizing slightly different samples of the population, with slightly different approaches.\n\nFor any individual poll we want to weight its contribution to the daily estimate based on known variables that affect responses (e.g: is this a partisan poll? is the poll registered or likely voters?), as well as \"random\" factors that sum to a distribution around a mean value (the distribution of responses by day, and by pollster). In addition, I wanted a model that also updated based on smooth time trends. While there are some nifty approaches using things like random-walk priors, I opted for a very simple cubic spine regression. \n\n### Fitting the models\n\nTo do this we fit the HLM component by applying fixed effects for partisan identification, the survey method (online, phone, or other), and the self-identified voting population (registered voters, likely voters, or adults). We apply varying intercepts for a day indicator, as well as for a pollster indicator. These varying intercepts apply partial pooling for each polling day as well as for pollster effects. In short, what this does is help pull polling estimates toward a group-level mean, and helps avoid any individual poll pulling the estimates too far in one direction - which is often referred to as \"shrinkage\". I've actually written about this before in a blog post about [estimating rare injury rates](https://gmcirco.github.io/blog/posts/hlm-osha/osha_shrinkage.html). We also fit a very simple cubic spline regression with default `brms` parameters. The idea here is to get smoothed estimates over time to account for a baseline trend of public opinion. \n\nWe do all the model fitting using brms using a binomial regression model in the form `n_votes |trials(pop)` where `n_votes` is the predicted number of votes for a candidate given a survey sample size `pop`. Finally, we also weight the polls based on their [numeric grade assigned by 538](https://projects.fivethirtyeight.com/pollster-ratings/). An example brms model looks something like the following below:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting a poll aggregation model for harris\nfit2.1 <-\n  brm(\n    n_votes |\n      trials(pop) + weights(W_dem) ~ 1 + partisan + method + vtype +\n      (1 | index_t) +\n      (1 | index_p),\n    family = \"binomial\",\n    data = all_polls_df[dem, ],\n    data2 = list(W_dem = W_dem),\n    prior = bprior,\n    chains = 4,\n    cores = 4,\n    file = \"data\\\\election_model\\\\fit2.1\"\n  )\n```\n:::\n\n\n\n### Post-hoc weighting\n\nI likely deviated from accepted statistical dogma here by weighting the smoothing spline model and HLM using very ad-hoc approach. Early on I decided that I wanted my estimates to be mostly evenly controlled by the HLM and the smoothing spline, but I felt that the smoothing time trend would help eliminate a lot of the spikes on a day-to-day basic. I opted for a 60/40 weighting scheme that gave slightly more weight to the smoothing model. As you can see below, the combined \"post-hoc\" weighted predictions.\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {layout=\"[[1,1], [1]]\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Smoothing spline model predictions](election_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Hierarchical linear model predictions](election_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Post-hoc weighted predictions (60/40)](election_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n:::\n\nFor clarity, we can add all the individual poll results showing the estimated support for Harris and Trump, with the size weighted by the number of respondents (larger polls get larger circles). Shown below, on the last day before the election we estimate a popular vote of 49.1% for Trump and 48.9% for Harris. Including the uncertainty basically makes estimating the winner essentially a coinflip. \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Predicted popular vote for Harris and Trump, as of 11/4/2024](election_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n### Results\n\nAnd below we have a table showing the estimated results for the last day of polling on 11/14/2025.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Election day estimates, national popular vote\n\n|party |end        |  ymin| median|  ymax|\n|:-----|:----------|-----:|------:|-----:|\n|DEM   |2024-11-04 | 47.34|  48.92| 50.59|\n|REP   |2024-11-04 | 47.49|  49.11| 50.76|\n\n\n:::\n:::\n\n\n\nLooking at my estimates, compared to the final count (as of 1/9/2025) the point estimates my model came up with are quite close to the observed results (Trump at 49.9% vs 49.1%, Harris at 48.9% vs 48.4%). Getting within a percentage point of the true value is pretty good, I think for a somewhat half-baked model! That being said, for the purposes of predicting who would ultimately win the day of, the margin of error on the predictions give us essentially no additional confidence beyond a 50/50 chance. This is pretty consistent with a lot of other pollsters who had fancier models. In the end, it was a very close election that was decided by a relatively small number of voters in key areas.\n\n## Full Script\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\n\npolls <- read_csv(\"https://projects.fivethirtyeight.com/polls-page/data/president_polls_historical.csv\")\nset.seed(8372)\n\n# set up data, consistent with some other data sources\n# this is just national polls\nmax_size = 5000\nmatchup = c(\"Harris\", \"Trump\")\n\n# get just harris-trump matchups\nharris_trump <-\npolls %>%\n  group_by(poll_id, question_id) %>%\n  summarise(all_reps = paste0(answer, collapse = \",\") ) %>%\n  filter(all_reps %in% c(\"Harris,Trump\",\"Trump,Harris\")) %>%\n  pull(question_id)\n\n\n# select data\n# only national polls where trump-harris are the options\n# remove polls that are overlapping\n\nall_polls_df <- \npolls %>%\n  rename(pop = sample_size,\n         vtype = population) %>%\n  mutate(begin = as.Date(start_date, \"%m/%d/%y\"),\n         end = as.Date(end_date, \"%m/%d/%y\"),\n         t = end - (1 + as.numeric(end-begin)) %/% 2,\n         entry_date = as.Date(created_at, \"%m/%d/%y\")) %>%\n  filter(question_id %in% harris_trump,\n         is.na(state),\n         !is.na(pollscore),\n         !is.na(numeric_grade),\n         answer %in% matchup,\n         end > as.Date(\"2024-06-01\"),\n         t >= begin & !is.na(t) & (vtype %in% c(\"lv\",\"rv\",\"a\")),\n         pop > 1,\n         pop <= max_size) %>%\n  mutate(pollster = str_extract(pollster, pattern = \"[A-z0-9 ]+\") %>% sub(\"\\\\s+$\", \"\", .),\n         pollster = replace(pollster, pollster == \"Fox News\", \"FOX\"), \n         pollster = replace(pollster, pollster == \"WashPost\", \"Washington Post\"),\n         pollster = replace(pollster, pollster == \"ABC News\", \"ABC\"),\n         partisan = ifelse(is.na(partisan), \"NP\", partisan),\n         method = case_when(\n           str_detect(tolower(methodology) ,\"online\") ~ \"online\",\n           str_detect(tolower(methodology) ,\"phone\") ~ \"phone\",\n           TRUE ~ \"other\"),\n         week = floor_date(t - days(2), unit = \"week\") + days(2),\n         day_of_week = as.integer(t - week),\n         index_t = 1 + as.numeric(t) - min(as.numeric(t)),\n         index_w = as.numeric(as.factor(week)),\n         index_p = as.numeric(as.factor(as.character(pollster))),\n         n_votes =  round(pop * (pct/100))) %>%\n  distinct(t, pollster, pop, party, .keep_all = TRUE) %>%\n  select(poll_id, t, begin, end, entry_date, pollster, partisan, numeric_grade, pollscore, vtype, method, pop, n_votes, pct,party,answer, week, day_of_week, starts_with(\"index_\"))\n\n# remove overlapping polls\nall_polls_df <-\n  all_polls_df %>%\n  group_by(entry_date, pollster, pop, party) %>%\n  arrange(desc(entry_date), desc(end)) %>%\n  slice(1)\n\n# drop polls with combined 2-party vote share < 85%\nlow_vote <-\n  all_polls_df %>%\n  group_by(poll_id, entry_date, pollster, pop) %>%\n  summarise(total_votes = sum(n_votes), .groups = 'drop') %>%\n  mutate(prop = total_votes / pop) %>%\n  filter(prop < .85) %>%\n  select(poll_id, entry_date, pollster, pop)\n\nall_polls_df <- anti_join(all_polls_df, low_vote)\n\n# plot the 2 party pct\nall_polls_df %>%\n  ggplot(aes(x = t, y = pct, color = party)) +\n  geom_point(aes(size = pop, fill = party),shape = 21, alpha = .2) +\n  geom_smooth(aes(color = party)) +\n  scale_color_manual(values = c(\"#00AEF3\",\"#E81B23\")) +\n  scale_fill_manual(values = c(\"#00AEF3\",\"#E81B23\")) +\n  scale_y_continuous(limits = c(30, 60)) +\n  theme_minimal() +\n  theme(legend.position = 'none')\n\n\n\n# RUN MODELS\n# -------------------- #\n\nextract_posterior_predictions <- function(x){\n  # get the median and 95% credible interval\n  ypred <- posterior_predict(x)\n  ypred <- apply(ypred, 2, quantile, probs = c(.025, .5, .975)) %>% round()\n  data.frame(t(ypred)) %>% set_names(c(\"ymin\",\"median\",\"ymax\"))\n}\n\nstack_extract_posterior_predictions_naive <- function(x1, x2, weights = c(.5, .5), return = \"agg\"){\n  # average weighted predictions from two models\n  pred1 <- posterior_predict(x1)\n  pred2 <- posterior_predict(x2)\n  pred_avg <- (pred1 * weights[1]) + (pred2 * weights[2])\n  \n  if(return==\"agg\"){\n    ypred <- apply(pred_avg, 2, quantile, probs = c(.025, .5, .975)) %>% round()\n    out <- data.frame(t(ypred)) %>% set_names(c(\"ymin\",\"median\",\"ymax\"))\n  }\n  else if(return==\"raw\"){\n    out <- pred_avg\n  }\n  \n  return(out)\n}\n\nstack_extract_posterior_predictions <- function(x1, x2){\n  # get the median and 95% credible interval\n  ypred <- pp_average(x1, x2, summary = FALSE)\n  ypred <- apply(ypred, 2, quantile, probs = c(.025, .5, .975)) %>% round()\n  data.frame(t(ypred)) %>% set_names(c(\"ymin\",\"median\",\"ymax\"))\n}\n\n# politcal idx\ndem <- all_polls_df$party == 'DEM'\ngop <- all_polls_df$party == 'REP'\n\n# adjust for poll type, partisan\nbprior <- c(\n  prior(normal(0, 0.5), class = 'Intercept'),\n  prior(normal(0, 0.5), class = 'b'),               \n  prior(student_t(3, 0, 1), class = 'sd')                \n)\n\nsprior <- c(prior(normal(0, 0.5), class = 'Intercept'),\n            prior(student_t(3, 0, 1), class = 'sds'))\n\n# rescaled polster weights, mean of 1\nW <- all_polls_df$numeric_grade/mean(all_polls_df$numeric_grade, na.rm = TRUE)\nW_dem = W[dem]\nW_gop = W[gop]\n\n# aggregation model\nfit2.1 <-\n  brm(\n    n_votes |\n      trials(pop) + weights(W_dem) ~ 1 + partisan + method + vtype +\n      (1 | index_t) +\n      (1 | index_p),\n    family = \"binomial\",\n    data = all_polls_df[dem, ],\n    data2 = list(W_dem = W_dem),\n    prior = bprior,\n    chains = 4,\n    cores = 4,\n    file = \"data\\\\election_model\\\\fit2.1\"\n  )\n\nfit2.2 <-\n  brm(\n    n_votes |\n      trials(pop) + weights(W_gop) ~ 1 + partisan + method + vtype +\n      (1 | index_t) +\n      (1 | index_p),\n    family = \"binomial\",\n    data = all_polls_df[gop, ],\n    data2 = list(W_gop = W_gop),\n    prior = bprior,\n    chains = 4,\n    cores = 4,\n    file = \"data\\\\election_model\\\\fit2.2\"\n  )\n\n# using a cubic regression spline for smoothing\nfit2.1s <-\n  brm(n_votes | trials(pop) + weights(W_dem) ~ 1 + s(index_t, bs = 'cr'),\n    data = all_polls_df[dem, ],\n    data2 = list(W_dem = W_dem),\n    family = \"binomial\",\n    prior = sprior,\n    chains = 4,\n    cores = 4,\n    control = list(adapt_delta = 0.99),\n    file = \"data\\\\election_model\\\\fit2.1s\"\n  )\n\nfit2.2s <-\n  brm(n_votes |trials(pop) + weights(W_gop) ~ 1 + s(index_t, bs = 'cr'),\n    data = all_polls_df[gop, ],\n    family = \"binomial\",\n    prior = sprior,\n    data2 = list(W_gop = W_gop),\n    chains = 4,\n    cores = 4,\n    control = list(adapt_delta = 0.99),\n    file = \"data\\\\election_model\\\\fit2.2s\"\n  )\n\n# add predictions back to dataframe with weighted predictions\n# weight 1 = hlm, weight 2 = smoothing model\n# more weight on #2 = more smoothing\n# default is about 40% hlm, 60% smoothing\nweights = c(.4, .6)\npred_dem <- cbind.data.frame(stack_extract_posterior_predictions_naive(fit2.1, fit2.1s, weights = weights), all_polls_df[dem,])\npred_gop <- cbind.data.frame(stack_extract_posterior_predictions_naive(fit2.2, fit2.2s, weights = weights), all_polls_df[gop,])\n\n\ntest <-\n  rbind.data.frame(pred_dem, pred_gop)  %>%\n  mutate(across(ymin:ymax, function(x)\n    (x / pop)*100)) %>%\n  group_by(party, end) %>%\n  summarise(across(ymin:ymax, mean)) %>%\n  ungroup()\n\nplot1<-\ntest %>%\n  group_by(party, end) %>%\n  summarise(across(ymin:ymax, mean)) %>%\n  ggplot(aes(x = end)) +\n  geom_line(aes(y = median, group = party, color = party), linewidth = 1.2) +\n  scale_color_manual(values = c(\"#00AEF3\",\"#E81B23\")) +\n  scale_fill_manual(values = c(\"#00AEF3\",\"#E81B23\")) +\n  scale_y_continuous(limits = c(30, 60)) +\n  geom_hline(yintercept = 30, color = 'grey20') +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.major.y = element_line(color = \"grey90\", linewidth = 1 ),\n        panel.grid.minor.y = element_line(color = \"grey90\", linewidth = 1),\n        axis.ticks.x = element_line(lineend = \"round\", linewidth = 1, color = 'grey50'),\n        axis.title = element_blank(),\n        axis.text = element_text(size = 10, color = 'grey50', face = 'bold'),\n        axis.text.y = element_text(vjust = -0.5))\nplot1\n\n# labels for end points\nend_labels <- test %>%\n  filter(end == max(end)) %>%\n  group_by(party) %>%\n  slice(1)\n\n\n# w/o error bars\nplot1 +\n  geom_point(data = all_polls_df, aes(x = end, y = pct, color = party, fill = party), shape = 21, size = 2, alpha = .2) \n\n# add point sizes and label\nplot1 +\n  geom_point(data = all_polls_df, aes(x = end, y = pct, color = party, fill = party, size = pop), alpha = .2) +\n  geom_point(data = end_labels, aes(x = end, y = median, color = party), size = 2.5) +\n  geom_label(data = end_labels, aes(x = end, y = median, label = round(median,1), fill = party), color = 'white', fontface = 'bold', nudge_x = 5, nudge_y = c(-.75,.75), size = 3.2)\n\n # facet plots\nplot1 +\n  geom_point(data = all_polls_df, aes(x = end, y = pct, color = party, fill = party, size = pop), alpha = .2) +\n  geom_ribbon(aes(ymin = ymin, ymax = ymax, group = party, fill = party), color = 'white', alpha = .2)\n\n\n# difference on max data\nraw_dem <- stack_extract_posterior_predictions_naive(fit2.1, fit2.1s, weights = weights, return = \"raw\")\nraw_gop <- stack_extract_posterior_predictions_naive(fit2.2, fit2.2s, weights = weights, return = \"raw\")\n\n\n# compute dem margin based on most recent 10 days worth of polls\ndem_margin <- raw_dem / (raw_dem + raw_gop)\n\nmax_date <- max(pred_dem$end)\ndate_idx <- seq.Date(from = max_date,by = \"-1 day\",length.out = 10)\nT <- as.numeric(rownames(pred_dem[pred_dem$end %in% date_idx, ]))\n\nmean(apply(dem_margin[,T], 1, function(x) mean(x > .5)))\n\n# 95% CI and mean \n# predicted share of 2-party vote\nmean(apply(dem_margin[,T], 1, quantile, probs = c(0.025)))\nmean(apply(dem_margin[,T], 1, mean))\nmean(apply(dem_margin[,T], 1, quantile, probs = c(0.975)))\n\n# predicted % times that dem candidate wins popular vote\n# NOT the same as winning the election !!!\nmean(dem_margin[,T] > .5)\n\nhist(dem_margin)\n```\n:::\n\n\n\n## Comments {.unlisted}\n\n\n\n{{< bluesky-comments https://bsky.app/profile/giocirco.bsky.social/post/3lfdjxr56uk23 >}}\n\n",
    "supporting": [
      "election_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}